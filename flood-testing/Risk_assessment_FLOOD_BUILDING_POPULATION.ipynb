{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9da14a0-57c3-40c9-b4aa-b2d8499381a6",
   "metadata": {
    "id": "f9da14a0-57c3-40c9-b4aa-b2d8499381a6"
   },
   "source": [
    "# Risk assessment for flooding - building damage and population exposure\n",
    "\n",
    "- A workflow from the CLIMAAX [Handbook](https://handbook.climaax.eu/) and [FLOODS](https://github.com/CLIMAAX/FLOODS) GitHub repository.\n",
    "- See our [how to use risk workflows](https://handbook.climaax.eu/notebooks/workflows_how_to.html) page for information on how to run this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac8736b-b9e6-4adf-a8cc-b8d4a9173418",
   "metadata": {
    "id": "cac8736b-b9e6-4adf-a8cc-b8d4a9173418"
   },
   "source": [
    "## Introduction\n",
    "This workflow assesses economic damage to buildings, exposure of critical infrastructure, and population exposure & displacement, by combining flood map data (hazard) and population and building data (exposure).\n",
    "\n",
    "<figure class=\"align-center\">\n",
    "  <iframe width=\"560\" height=\"315\" src=\"https://www.youtube-nocookie.com/embed/JWQbkcf75T4?si=CaBLEpgdI90EHOmE\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n",
    "</figure>\n",
    "\n",
    "### Building damage & critical infrastructure\n",
    "Flood risk in the form of economic damage at a building level is computed from flood depth maps and building data. The damages are computed for each flood event (flood map for a given return period) and then integrated over all of the event return periods to determine expected annual damage (EAD). Damage to each building varies based on the local flood depth, reconstruction costs, value of its contents, and its footprint area.\n",
    "\n",
    "Datasets:\n",
    "- River flood extent and depth are from the [European Commission's Joint Research Centre](https://data.jrc.ec.europa.eu/dataset/1d128b6c-a4ee-4858-9e34-6210707f3c81) for different return periods at 3 arc-seconds resolution.\n",
    "- Building data, including type and footprint are obtained from [OpenStreetMap](https://www.openstreetmap.org/copyright).\n",
    "- Building damage fraction, reconstruction costs, and the value of its contents are determined using the [JRC methodology](https://publications.jrc.ec.europa.eu/repository/handle/JRC105688).\n",
    "\n",
    "Furthermore, critical infrastructure is mapped onto the flood maps to visually assess its exposure to the hazard.\n",
    "\n",
    "The code can be customized to use any flood map, building data, and depth-damage relationships.\n",
    "\n",
    "### Population exposure & population displaced\n",
    "Population exposure and displaced population are computed from flood maps and population maps. The population data by default is based on a global dataset and one can choose from a number of options for the time period (past years and projections for near future). Population is considered displaced when the population is exposed to flood depths over a given threshold. For both exposure and displacement, the results are integrated over all of the event return periods to determine expected annual population exposed (EAPE) and expected annual population displaced (EAPD).\n",
    "\n",
    "Datasets:\n",
    "- River flood extent and water depth are from the [European Commission's Joint Research Centre](https://data.jrc.ec.europa.eu/dataset/1d128b6c-a4ee-4858-9e34-6210707f3c81) for different event return periods at 3 arc-seconds resolution.\n",
    "- Population distribution maps are from the [European Commission's Joint Research Centre](https://data.jrc.ec.europa.eu/dataset/2ff68a52-5b5b-4a22-8f40-c41da8332cfe) at 3 arc-seconds resolution.\n",
    "\n",
    "The code can be customized to use any population data, flood map, and minimum water depth threshold to classify the exposed and displaced populations.\n",
    "\n",
    "### Limitations\n",
    "The flood maps that are used in this workflow by default do not take into consideration possible flood protection infrastructure that may in reality limit the impact of the hazard. Moreover, the resolution of 3 arc-seconds for both the flood maps and population maps may be unsitable for particularly complex regions. If possible, it is suggested to use local data which may lead to a better representation of the ground truth.\n",
    "\n",
    "Furthermore, buildings that are close to water bodies (e.g: rivers) may overlap the water body, thus resulting in higher than expected flood depths (and damage) values being used in the damage calculations. This effect can be reduced by using higher resolution flood maps. \n",
    "Similarly, due to the resolution of both the population and the flood maps, it might be that part of the population appears to be over a water body and is counted towards the overall exposed and displaced statistics irregardless of flooding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71969341-28c7-47e3-8ae7-57a307856f8e",
   "metadata": {
    "id": "71969341-28c7-47e3-8ae7-57a307856f8e"
   },
   "source": [
    "## Preparation work\n",
    "### Import modules\n",
    "\n",
    "`````{admonition} Find more info about the libraries used in this workflow here\n",
    ":class: hint dropdown\n",
    "\n",
    "These modules are needed to process the data in this workflow and to plot the results.\n",
    "- [os](https://docs.python.org/3/library/os.html): For interacting with the operating system, allowing the creation of directories and file manipulation.\n",
    "- [sys](https://docs.python.org/3/library/sys.html): Provides access to some variables used or maintained by the interpreter and to functions that interact strongly with the interpreter. It is always available.\n",
    "- [numpy](https://numpy.org/): A powerful library for numerical computations in Python, widely used for array operations and mathematical functions.\n",
    "- [pandas](https://pandas.pydata.org/): A data manipulation and analysis library, essential for working with structured data in tabular form.\n",
    "- [geopandas](https://geopandas.org): Extends the datatypes used by pandas to allow spatial operations on geometric types.\n",
    "- [rasterio](https://rasterio.readthedocs.io/en/stable/): For reading and writing geospatial raster data, providing functionalities to explore and manipulate raster datasets.\n",
    "- [rasterstats](https://pythonhosted.org/rasterstats): For summarizing geospatial raster datasets based on vector geometries.\n",
    "- [shapely](https://pypi.org/project/shapely/): For manipulation and analysis of planar geometric objects.\n",
    "- [osgeo](https://www.osgeo.org/): For translating raster and vector geospatial data formats.\n",
    "- [osmnx](https://osmnx.readthedocs.io/) To easily download, model, analyze, and visualize street networks and other geospatial features from OpenStreetMap.\n",
    "- [pyproj](https://pyproj4.github.io/pyproj/dev/index.html): Interface for PROJ (cartographic projections and coordinate transformations library).\n",
    "- [matplotlib](https://matplotlib.org/): Used for creating static, animated, and interactive visualizations.\n",
    "- [contextily](https://contextily.readthedocs.io/en/latest/): For adding basemaps to plots, enhancing geospatial visualizations.\n",
    "- [urllib.request](https://docs.python.org/3/library/urllib.request.html): Defines functions and classes which help in opening URLs (mostly HTTP) in a complex world â€” basic and digest authentication, redirections, cookies and more.\n",
    "- [zipfile](https://docs.python.org/3/library/zipfile.html): Provides tools to create, read, write, append, and list a ZIP file.\n",
    "- [socket](https://docs.python.org/3/library/socket.html): pPovides access to the BSD socket interface.\n",
    "\n",
    "`````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413894c3-b07c-4132-9d78-16055583b522",
   "metadata": {
    "id": "413894c3-b07c-4132-9d78-16055583b522"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "from zipfile import ZipFile\n",
    "import socket\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.windows import from_bounds\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio.warp import reproject, calculate_default_transform\n",
    "from rasterio.mask import mask\n",
    "from rasterio.transform import array_bounds\n",
    "import rasterstats\n",
    "from osgeo import gdal, osr\n",
    "from shapely.geometry import Polygon, Point\n",
    "import osmnx as ox\n",
    "from pyproj import Transformer\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as pe\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import contextily as ctx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37661e1-5013-4c03-a0b0-16f92af9e67b",
   "metadata": {
    "id": "b37661e1-5013-4c03-a0b0-16f92af9e67b"
   },
   "source": [
    "### Define inputs\n",
    "In this section different input parameters are set. Please read the descriptions when provided to ensure the appropriate changes are made. \n",
    "Some of the things that can be set here are:\n",
    "- Geographical bounds of area of interest (a .shp or .gpkg file can be used for polygons delineating the area of interest, alternatively coordinates can be manually inserted for a rectangular outline).\n",
    "- Return periods for which calculations are made, projection of the population.\n",
    "- Code flags (e.g. choosing which maps get produced, what elements are shown in outputs, automatically saving images, etc.)\n",
    "- Directory locations\n",
    "- Colorbars for maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c199ee81-d50d-4e1b-92f0-3b4e58650168",
   "metadata": {
    "id": "c199ee81-d50d-4e1b-92f0-3b4e58650168"
   },
   "outputs": [],
   "source": [
    "## Name for saves\n",
    "saveName = 'venice'\n",
    "# Example usage:\n",
    "file_path = \"data/venice.geojson\"  # or \"path/to/your/file.shp\"\n",
    "# make sure file is 4326\n",
    "gdf = gpd.read_file(file_path)\n",
    "print(gdf.crs)\n",
    "\n",
    "\n",
    "def get_spatial_bounds(file_path):\n",
    "    \"\"\"\n",
    "    Reads a GeoJSON or Shapefile and extracts the min/max latitude and longitude.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the spatial file (.geojson or .shp).\n",
    "\n",
    "    Returns:\n",
    "        tuple: (min_latitude, max_latitude, min_longitude, max_longitude)\n",
    "    \"\"\"\n",
    "    # Load the file into a GeoDataFrame\n",
    "    gdf = gpd.read_file(file_path)\n",
    "\n",
    "    # Compute bounding box (minx, miny, maxx, maxy)\n",
    "    minx, miny, maxx, maxy = gdf.total_bounds  # (min_long, min_lat, max_long, max_lat)\n",
    "\n",
    "    return miny, maxy, minx, maxx  # (Latitude1, Latitude2, Longitude1, Longitude2)\n",
    "\n",
    "\n",
    "Latitude1, Latitude2, Longitude1, Longitude2 = get_spatial_bounds(file_path)\n",
    "\n",
    "print(f\"Bounding Box: ({Latitude1}, {Latitude2}, {Longitude1}, {Longitude2})\")\n",
    "outlineGeometry=gpd.GeoSeries(\n",
    "    [Polygon([(Longitude1, Latitude1), (Longitude2, Latitude1),\n",
    "              (Longitude2, Latitude2), (Longitude1, Latitude2)])],crs='EPSG:4326')\n",
    "\n",
    "\n",
    "## Location, either from file or from coordinates ------------------\n",
    "#outlineFileFlag=False #If true, the outline found in the file location below will be used. If false, the rectangle created by the input coordinates will be used\n",
    "\n",
    "#if outlineFileFlag is True: \n",
    " #   outlineFileLoc='layers/POLYGON.shp' #Input location of shapefile/geopackage with outline of interest\n",
    " #   try:\n",
    " #       outlineFile=gpd.read_file(outlineFileLoc)\n",
    " #   except Exception as exc:\n",
    " #       raise ValueError(\"Could not open outline file location (shapefile or geopackage). If you want to manually define a box with coordinates, set the outlineFileFlag to False, and set Latitude1, Latitude2, Longitude1, Longitude2 with your chosen coordinates.\") from exc\n",
    " #   outlineGeometry=outlineFile.geometry.to_crs(4326)\n",
    " #   if outlineGeometry.ndim>1:\n",
    " #       raise ValueError(f\"Make sure the given file contains only the outline needed, so that the dimension of the variable is 1. Current dimensions: {outlineGeometry.ndim}\")\n",
    " #   outlineBounds=outlineGeometry.bounds\n",
    " #   Latitude1, Latitude2 = outlineBounds['miny'].min(),outlineBounds['maxy'].max()\n",
    " #   Longitude1, Longitude2 = outlineBounds['minx'].min(),outlineBounds['maxx'].max()\n",
    " #   print('using supplied shapefile')\n",
    "\n",
    "#elif outlineFileFlag is False: \n",
    "    # Placeholder example, Italy\n",
    "    #Latitude1, Longitude1 = 43.77, 11.265 # Input coordinates of location, in EPSG:4326\n",
    "    #Latitude2, Longitude2 = 43.78, 11.29 # Input coordinates of location, in EPSG:4326\n",
    "    \n",
    "    #Latitude1, Latitude2 = min(Latitude1, Latitude2), max(Latitude1, Latitude2)\n",
    "    #Longitude1, Longitude2 = min(Longitude1, Longitude2), max(Longitude1, Longitude2)\n",
    "    #outlineGeometry=gpd.GeoSeries(\n",
    "   # [Polygon([(Longitude1, Latitude1), (Longitude2, Latitude1),\n",
    "  #            (Longitude2, Latitude2), (Longitude1, Latitude2)])],crs='EPSG:4326')\n",
    " #   print('using some default box')\n",
    "#else:\n",
    "    #raise ValueError(f\"outlineFileFlag must be set as either True or False. Currently: {outlineFileFlag}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Return Periods of Interest ------------------------------------\n",
    "# Return period levels, if using original source pick from [10, 20, 30, 40, 50, 75, 100, 200, 500]\n",
    "ReturnPeriods = [10, 50, 100, 500]  \n",
    "\n",
    "## Population estimate/projection year ---------------------------\n",
    "#Can choose any year with a 5 year interval between 1975 and 2030 (estimates until 2020, projections after 2020)\n",
    "PopYear = 2025 #Remember this only changes the population dataset, building data and flood data remain unchanged\n",
    "\n",
    "if not (isinstance(PopYear, int) and 1975 <= PopYear <= 2030 and PopYear % 5 == 0):\n",
    "    raise ValueError(\"The variable must be an integer, between 1975 and 2030, and a multiple of 5.\")\n",
    "\n",
    "## Water Depths to Compute damages, based on Mean, Maximum, and/or Minimum depths at a building's location \n",
    "# Mean will assume the water depth at a building's location to be the mean of it's max and min value. Max will assume the whole building's location has water depth value as at it's largest value, and viceversa for Min\n",
    "Depths = ['Mean'] #Options are ['Mean', 'Max', 'Min'], can run multiple options at the same time to compare results in the building damage graph\n",
    "\n",
    "\n",
    "## Water Depths for Exposed and Displaced Population---------------\n",
    "# If depth is greater than this, the population is exposed\n",
    "minDepthExposed = 0.0 \n",
    "# If depth is greater than this, the population is displaced\n",
    "minDepthDisplaced = 1.0 \n",
    "\n",
    "\n",
    "## Figure Options ------------------------------------------\n",
    "# Save images in folder (True saves)\n",
    "imageSaveFlag = True\n",
    "\n",
    "# Return period for the optional figures. If using original source pick from [10, 20, 30, 40, 50, 75, 100, 200, 500]\n",
    "ImageReturnPeriod = [10, 500] #At least one input, value/s MUST also be present in RetrunPeriods \n",
    "\n",
    "for value in ImageReturnPeriod:\n",
    "    if value not in ReturnPeriods:\n",
    "        raise ValueError(f\"Value {value} in ImageReturnPeriod is not present in ReturnPeriods, i.e. workflow is trying to create graphics from a return period not being analysed.\\nEither remove it from ImageReturnPeriod, or add it into ReturnPeriod.\")\n",
    "\n",
    "# Buffer size. How much additional space is given around the location of interest in the maps, for nicer looking map outputs. (in EPSG:4326)\n",
    "ybuffer=0.0020\n",
    "xbuffer=0.0040\n",
    "\n",
    "# Outline of location settings\n",
    "showOutlineFlag=True #Set to True to show outline, False to hide it\n",
    "outlineColour='limegreen' #Colour of outline\n",
    "outlineStyle='-' #Style of the outline. Choose from -, :, --, -.\n",
    "outlineThickness=3 #Line thickness of outline\n",
    "outlineFace='none' #Face colour of outline\n",
    "outlineAlpha=1 #Transparency of edge and face colour for the outline\n",
    "outlineLabelFlag=True #True prints the outline label, False hides it\n",
    "outlineLabel=f'{saveName} Outline' #Text used for the label of the outline\n",
    "outlineLabelSize=8 #Fontsize of otuline label\n",
    "outlineLabelPosition='upper left' #Position of the label within the map, suggested either 'upper left' or 'lower right'\n",
    "legend_outline = None\n",
    "\n",
    "# Maximum Water level in legend. Useful if big discrepancy between river and flood depths exists.\n",
    "customMaxDepthLegend=-1 #Set as -1 to automatically set highest value found in data as the legend's maximum\n",
    "\n",
    "# Damage curves (True prints)\n",
    "flagDamageCurve = True\n",
    "\n",
    "# Building Images (True prints)\n",
    "    #Building maps with classification \n",
    "flagBuilding = True\n",
    "    #Building maps with flood level\n",
    "flagBuildingH2o = True\n",
    "    #Building maps with damage received\n",
    "flagBuildingDmg = True\n",
    "    #Annual damage by return period graph\n",
    "flagBuildingDmgGraph = True\n",
    "\n",
    "# Population Images (True prints)\n",
    "    #Population exposed map\n",
    "flagPopulationExp = True\n",
    "    #Annual population exposed graph\n",
    "flagPopulationExpGraph = True\n",
    "    #Population displaced map\n",
    "flagPopulationDis = True\n",
    "    #Annual population displaced graph\n",
    "flagPopulationDisGraph = True\n",
    "\n",
    "## Figure Colour Scheme -------------------------------\n",
    "# Water Depth Colorbar for Maps\n",
    "cmap_h2o = LinearSegmentedColormap.from_list('gist_stern_inv',['blue', 'red'], N=256)  #cmap_h2o='Blues' can also be a good option.\n",
    "# Building Class Colorbar for Maps\n",
    "cmap_cls = LinearSegmentedColormap.from_list('gist_stern_inv',['orange','purple', 'blue', 'red'], N=256)\n",
    "# Population Colorbar for Maps\n",
    "cmap_pop = LinearSegmentedColormap.from_list('gist_stern_inv',['orange', 'red','fuchsia'], N=256)\n",
    "# Damage Colorbar for Maps\n",
    "cmap_dmg = LinearSegmentedColormap.from_list('gist_stern_inv',['blue', 'red','fuchsia'], N=256)\n",
    "\n",
    "\n",
    "## Data Management ----------------------------------\n",
    "RP, tile_id_max = True,0 #Temporary initiation, will automatically change in workflow\n",
    "\n",
    "# Directory of main folder (working directory)\n",
    "dirWork = '.'\n",
    "os.chdir(dirWork)\n",
    "\n",
    "# Input Hazard Path\n",
    "dirDepths = os.path.join(dirWork, 'data')\n",
    "if not os.path.exists(dirDepths):\n",
    "    os.makedirs(dirDepths)\n",
    "\n",
    "# OSM Output Path\n",
    "dirOSM = os.path.join(dirWork, 'OSM')\n",
    "if not os.path.exists(dirOSM):\n",
    "    os.makedirs(dirOSM)\n",
    "\n",
    "# Results directory\n",
    "dirResults = os.path.join(dirWork, 'DamageBuildings')\n",
    "if not os.path.exists(dirResults):\n",
    "    os.makedirs(dirResults)\n",
    "dirResultsPop = os.path.join(dirWork, 'ExposePopulation')\n",
    "if not os.path.exists(dirResultsPop):\n",
    "    os.makedirs(dirResultsPop)\n",
    "\n",
    "# Saved images directory\n",
    "dirImages = os.path.join(dirWork, 'Images')\n",
    "if not os.path.exists(dirImages):\n",
    "    os.makedirs(dirImages)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bb39b0-e116-4989-bc06-cf1450fc3794",
   "metadata": {
    "id": "e2bb39b0-e116-4989-bc06-cf1450fc3794"
   },
   "source": [
    "## Download data\n",
    "In this section, the data required to run the analysis is downloaded. \n",
    "- Download flood depth and population rasters to the data folder if the file doesn't exist.\n",
    "- River flood extent and water depth are from the [Copernicus Land Monitoring Service](https://data.jrc.ec.europa.eu/dataset/1d128b6c-a4ee-4858-9e34-6210707f3c81) for different return periods, with 3 arc-seconds resolution (30-75m in Europe).\n",
    "- Population densities are from the [European Commission's Joint Research Centre](https://data.jrc.ec.europa.eu/dataset/2ff68a52-5b5b-4a22-8f40-c41da8332cfe), with 3 arc-seconds resolution (30-75m in Europe).\n",
    "\n",
    "This section can be modified to use local data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf23ddb-fc8b-489e-b8ea-d4c31c9421b0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "caf23ddb-fc8b-489e-b8ea-d4c31c9421b0",
    "outputId": "db1823b0-6190-4d16-c9a8-1429d3a19bbc"
   },
   "outputs": [],
   "source": [
    "#This workflow is using European data. Personal and local data is recommended.\n",
    "#Note: There is a known issue with Mollweide projections. Standard projection used is 'EPSG:4326'\n",
    "\n",
    "timeout = 90    # Download time out in seconds\n",
    "max_retries = 5  # Maximum number of download attempts\n",
    "socket.setdefaulttimeout(timeout)\n",
    "\n",
    "##Flood data download\n",
    "urlData='https://jeodpp.jrc.ec.europa.eu/ftp/jrc-opendata/CEMS-EFAS/flood_hazard/'\n",
    "\n",
    "for RP in ReturnPeriods:\n",
    "    print(f'Return Period={str(RP)}')\n",
    "    rastDepths = os.path.join(dirDepths, f'Europe_RP{RP}_filled_depth.tif')\n",
    "    if os.path.exists(rastDepths):\n",
    "        print(f'Flood depth raster already exists (skipping download): {rastDepths}')\n",
    "    else:\n",
    "        rastTif = f'Europe_RP{RP}_filled_depth.tif'\n",
    "        pathRastTif = os.path.join(dirDepths, rastTif)\n",
    "        urlRastTif = os.path.join(urlData, rastTif)\n",
    "        print(urlRastTif)\n",
    "        for attempt in range(1, max_retries + 1):\n",
    "            print(f'    Attempt: {attempt}')\n",
    "            try:\n",
    "                urllib.request.urlretrieve(urlRastTif, pathRastTif)\n",
    "                break  # Break loop if download is successful\n",
    "            except Exception as exc:\n",
    "                print('      Timeout.  Retry data download')\n",
    "                if attempt == max_retries:\n",
    "                    print('    Maximum number of timeouts reached.  Data download failed')\n",
    "                    print(f'      Consider increasing timeout value {timeout} seconds')\n",
    "                    print(f'      Consider increasing maximum number of download attempts {max_retries}')\n",
    "                    raise Exception(f'Timeout time {timeout} seconds exceeded {max_retries}') from exc\n",
    "        print('  Unzipping downloaded file')\n",
    "\n",
    "\n",
    "##Population data download ------------------------\n",
    "def download_pop_rast(tile_id):#Downloading the raster files for Population\n",
    "    print(f'Population tile id: {tile_id}')\n",
    "    urlDataPop=f'https://jeodpp.jrc.ec.europa.eu/ftp/jrc-opendata/GHSL/GHS_POP_GLOBE_R2023A/GHS_POP_E{PopYear}_GLOBE_R2023A_4326_3ss/V1-0/tiles/'\n",
    "    rastPopulation= os.path.join(dirDepths, f'GHS_POP_E{PopYear}_GLOBE_R2023A_4326_3ss_V1_0_{tile_id}.tif')\n",
    "    if os.path.exists(rastPopulation):\n",
    "        print('Population raster already exists (skipping download)')\n",
    "    else:\n",
    "        rastZip = f'GHS_POP_E{PopYear}_GLOBE_R2023A_4326_3ss_V1_0_{tile_id}.zip'\n",
    "        pathRastZip = os.path.join(dirDepths, rastZip)\n",
    "        urlRastZip = os.path.join(urlDataPop, rastZip)\n",
    "        print(urlRastZip)\n",
    "        for attempt in range(1, max_retries + 1):\n",
    "            print(f'    Attempt: {attempt}')\n",
    "            try:\n",
    "                urllib.request.urlretrieve(urlRastZip, pathRastZip)\n",
    "                break  # Break loop if download is successful\n",
    "            except Exception as exc:\n",
    "                print('      Timeout.  Retry data download')\n",
    "                if attempt == max_retries:\n",
    "                    print('    Maximum number of timeouts reached.  Data download failed')\n",
    "                    print(f'      Consider increasing timeout value {timeout} seconds')\n",
    "                    print(f'      Consider increasing maximum number of download attempts {max_retries}')\n",
    "                    raise Exception(f'Timeout time {timeout} seconds exceeded {max_retries}') from exc\n",
    "        print('  Unzipping downloaded file')\n",
    "        with ZipFile(pathRastZip, 'r') as zip_ref:\n",
    "            zip_ref.extract(f'GHS_POP_E{PopYear}_GLOBE_R2023A_4326_3ss_V1_0_{tile_id}.tif',dirDepths)\n",
    "\n",
    "def stitch_on_right(file1, file2, output_file):\n",
    "    if os.path.exists(output_file):\n",
    "        print('Stitched population raster already exists (skipping download)')\n",
    "    else:\n",
    "        with rasterio.open(file1) as src1, rasterio.open(file2) as src2:\n",
    "            # Get metadata and transform of the first raster\n",
    "            meta = src1.meta.copy()\n",
    "\n",
    "            # Calculate new dimensions for the stitched raster\n",
    "            new_width = src1.width + src2.width\n",
    "            new_height = max(src1.height, src2.height)\n",
    "\n",
    "            # Update metadata with new dimensions\n",
    "            meta.update(width=new_width, height=new_height)\n",
    "\n",
    "            # Create output raster\n",
    "            with rasterio.open(output_file, 'w', **meta) as dst:\n",
    "                # Write the first raster to the output raster\n",
    "                dst.write(src1.read(), window=rasterio.windows.Window(col_off=0, row_off=0, width=src1.width, height=src1.height))\n",
    "\n",
    "                # Write the second raster to the output raster\n",
    "                for i in range(1, src2.count + 1):\n",
    "                    dst.write(src2.read(i), i, window=rasterio.windows.Window(col_off=src1.width, row_off=0, width=src2.width, height=src2.height))\n",
    "\n",
    "def stitch_on_top(file1, file2, output_file):#Stitching two rasters vertically\n",
    "    if os.path.exists(output_file):\n",
    "        print('Stitched population raster already exists (skipping download)')\n",
    "    else:\n",
    "        with rasterio.open(file1) as src1, rasterio.open(file2) as src2:\n",
    "            # Get metadata and transform of the first raster\n",
    "            meta = src2.meta.copy()\n",
    "\n",
    "            # Calculate new dimensions for the stitched raster\n",
    "            new_width = max(src1.width, src2.width)\n",
    "            new_height = src1.height + src2.height\n",
    "\n",
    "            # Update metadata with new dimensions\n",
    "            meta.update(width=new_width, height=new_height)\n",
    "\n",
    "            # Create output raster\n",
    "            with rasterio.open(output_file, 'w', **meta) as dst:\n",
    "                # Write the second raster to the output raster\n",
    "                dst.write(src2.read(), window=rasterio.windows.Window(col_off=0, row_off=0, width=src2.width, height=src2.height))\n",
    "\n",
    "                # Write the first raster to the output raster\n",
    "                for i in range(1, src1.count + 1):\n",
    "                    dst.write(src1.read(i), i, window=rasterio.windows.Window(col_off=0, row_off=src1.height, width=src1.width, height=src1.height))\n",
    "\n",
    "def stitch_all(file1, file2, file3, file4, output_file):#Stitching four rasters\n",
    "    if os.path.exists(output_file):\n",
    "        print('Stitched population raster already exists (skipping download)')\n",
    "    else:\n",
    "        with rasterio.open(file1) as src1, rasterio.open(file2) as src2, rasterio.open(file3) as src3, rasterio.open(file4) as src4:\n",
    "            # Get metadata and transform of the first raster\n",
    "            meta = src3.meta.copy()\n",
    "\n",
    "            # Calculate new dimensions for the stitched raster\n",
    "            new_width = src3.width + src4.width\n",
    "            new_height = src1.height + src3.height\n",
    "\n",
    "            # Update metadata with new dimensions\n",
    "            meta.update(width=new_width, height=new_height)\n",
    "\n",
    "            # Create output raster\n",
    "            with rasterio.open(output_file, 'w', **meta) as dst:\n",
    "                # Write the first raster to the output raster\n",
    "                dst.write(src3.read(), window=rasterio.windows.Window(col_off=0, row_off=0, width=src3.width, height=src3.height))\n",
    "\n",
    "                # Write the second raster to the output raster\n",
    "                for i in range(1, src4.count + 1):\n",
    "                    dst.write(src4.read(i), i, window=rasterio.windows.Window(col_off=src3.width, row_off=0, width=src4.width, height=src4.height))\n",
    "\n",
    "                # Write the third raster to the output raster\n",
    "                for i in range(1, src1.count + 1):\n",
    "                    dst.write(src1.read(i), i, window=rasterio.windows.Window(col_off=0, row_off=src3.height, width=src1.width, height=src1.height))\n",
    "                \n",
    "                # Write the fourth raster to the output raster\n",
    "                for i in range(1, src2.count + 1):\n",
    "                    dst.write(src2.read(i), i, window=rasterio.windows.Window(col_off=src1.width, row_off=src3.height, width=src2.width, height=src2.height))\n",
    "\n",
    "urlDataPopScheme='https://ghsl.jrc.ec.europa.eu/download/'\n",
    "shpPopScheme = os.path.join(dirDepths, 'WGS84_tile_schema.shp')\n",
    "if os.path.exists(shpPopScheme):\n",
    "    print('Population scheme shapefile already exists (skipping download)')\n",
    "else:\n",
    "    rastZip = 'GHSL_data_4326_shapefile.zip'\n",
    "    pathRastZip = os.path.join(dirDepths, rastZip)\n",
    "    urlRastZip = os.path.join(urlDataPopScheme, rastZip)\n",
    "    print(urlRastZip)\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        print(f'    Attempt: {attempt}')\n",
    "        try:\n",
    "            urllib.request.urlretrieve(urlRastZip, pathRastZip)\n",
    "            break  # Break loop if download is successful\n",
    "        except Exception as exc:\n",
    "            print('      Timeout.  Retry data download')\n",
    "            if attempt == max_retries:\n",
    "                print('    Maximum number of timeouts reached.  Data download failed')\n",
    "                print(f'      Consider increasing timeout value {timeout} seconds')\n",
    "                print(f'      Consider increasing maximum number of download attempts {max_retries}')\n",
    "                raise Exception(f'Timeout time {timeout} seconds exceeded {max_retries}') from exc\n",
    "    print('  Unzipping downloaded file')\n",
    "    with ZipFile(pathRastZip, 'r') as zip_ref:\n",
    "        zip_ref.extractall(dirDepths)\n",
    "\n",
    "# Load the shapefile\n",
    "gdf = gpd.read_file(shpPopScheme)\n",
    "\n",
    "# Iterate through each polygon and check if the point is inside\n",
    "tile_id_min, tile_id_max = None, None \n",
    "for index, row in gdf.iterrows():\n",
    "    left, top, right, bottom = row['left'], row['top'], row['right'], row['bottom']\n",
    "    if left <= Longitude1 <= right and bottom <= Latitude1 <= top:\n",
    "        tile_id_min = row['tile_id']\n",
    "    if left <= Longitude2 <= right and bottom <= Latitude2 <= top:\n",
    "        tile_id_max = row['tile_id']\n",
    "    if tile_id_min is not None and tile_id_max is not None:\n",
    "        break\n",
    "\n",
    "tileMax=tile_id_max.split('_')\n",
    "Rmax, Cmax = tileMax[0][1:].split('R')[0], tileMax[1][1:].split('C')[0]\n",
    "tileMin=tile_id_min.split('_')\n",
    "Rmin, Cmin = tileMin[0][1:].split('R')[0], tileMin[1][1:].split('C')[0]\n",
    "\n",
    "if tile_id_min == tile_id_max:\n",
    "    download_pop_rast(tile_id_max)\n",
    "    rastPopulation= os.path.join(dirDepths, f'GHS_POP_E{PopYear}_GLOBE_R2023A_4326_3ss_V1_0_{tile_id_max}.tif')\n",
    "\n",
    "elif Rmin == Rmax and Cmin < Cmax:  # Stitch on the right\n",
    "    download_pop_rast(tile_id_max)\n",
    "    download_pop_rast(tile_id_min)  \n",
    "    file1 = os.path.join(dirDepths, f'GHS_POP_E{PopYear}_GLOBE_R2023A_4326_3ss_V1_0_{tile_id_min}.tif')\n",
    "    file2 = os.path.join(dirDepths, f'GHS_POP_E{PopYear}_GLOBE_R2023A_4326_3ss_V1_0_{tile_id_max}.tif')\n",
    "    rastPopulation = os.path.join(dirDepths, f'GHS_POP_E{PopYear}_GLOBE_R2023A_4326_3ss_V1_0_{tile_id_min}_to_{tile_id_max}.tif')\n",
    "    stitch_on_right(file1, file2, rastPopulation)\n",
    "    print(f'Stitched horizontally tiles {tile_id_min} and {tile_id_max}.')\n",
    "elif Rmin > Rmax and Cmin == Cmax: # Stitch on the top\n",
    "    download_pop_rast(tile_id_max)\n",
    "    download_pop_rast(tile_id_min) \n",
    "    file1 = os.path.join(dirDepths, f'GHS_POP_E{PopYear}_GLOBE_R2023A_4326_3ss_V1_0_{tile_id_min}.tif')\n",
    "    file2 = os.path.join(dirDepths, f'GHS_POP_E{PopYear}_GLOBE_R2023A_4326_3ss_V1_0_{tile_id_max}.tif')\n",
    "    rastPopulation = os.path.join(dirDepths, f'GHS_POP_E{PopYear}_GLOBE_R2023A_4326_3ss_V1_0_{tile_id_min}_to_{tile_id_max}.tif')\n",
    "    stitch_on_top(file1, file2, rastPopulation)\n",
    "    print(f'Stitched vertically tiles {tile_id_min} and {tile_id_max}.')\n",
    "elif Rmin > Rmax and Cmin < Cmax:\n",
    "    download_pop_rast(tile_id_max)\n",
    "    download_pop_rast(tile_id_min)\n",
    "    tile_id_tmp1=f'R{Rmin}_C{Cmax}'\n",
    "    tile_id_tmp2=f'R{Rmax}_C{Cmin}'\n",
    "    download_pop_rast(tile_id_tmp1)\n",
    "    download_pop_rast(tile_id_tmp2)\n",
    "    file1 = os.path.join(dirDepths, f'GHS_POP_E{PopYear}_GLOBE_R2023A_4326_3ss_V1_0_{tile_id_min}.tif')\n",
    "    file2 = os.path.join(dirDepths, f'GHS_POP_E{PopYear}_GLOBE_R2023A_4326_3ss_V1_0_{tile_id_tmp1}.tif')\n",
    "    file3 = os.path.join(dirDepths, f'GHS_POP_E{PopYear}_GLOBE_R2023A_4326_3ss_V1_0_{tile_id_tmp2}.tif')\n",
    "    file4 = os.path.join(dirDepths, f'GHS_POP_E{PopYear}_GLOBE_R2023A_4326_3ss_V1_0_{tile_id_max}.tif')\n",
    "    rastPopulation = os.path.join(dirDepths, f'GHS_POP_E{PopYear}_GLOBE_R2023A_4326_3ss_V1_0_{tile_id_min}_{tile_id_tmp1}_to_{tile_id_max}_{tile_id_tmp2}.tif')\n",
    "    stitch_all(file1,file2,file3,file4,rastPopulation)\n",
    "    print(f'Stitched together tiles {tile_id_min}, {tile_id_tmp1}, {tile_id_max}, {tile_id_tmp2}.')\n",
    "    print(f'Filen location: {rastPopulation}')\n",
    "else:\n",
    "    raise ValueError(f\"Location crosses population rasters {tile_id_min} and {tile_id_max}. Modify location or use personal data.)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d051d5eb-90c6-408d-a72a-f32aa0490182",
   "metadata": {
    "id": "d051d5eb-90c6-408d-a72a-f32aa0490182"
   },
   "source": [
    "## Define depth-damage functions\n",
    "Damage caused to buildings can be determined in relation to flood depth that the buildings are subjected to. In this section the relationship between water depth and damage are determined.\n",
    "\n",
    "Maximum damage values are based on:\n",
    "- Huizinga, J., Moel, H. de, Szewczyk, W. (2017). Global flood depth-damage functions. Methodology and the database with guidelines. EUR 28552 EN. doi: 10.2760/16510\n",
    "With following assumed values:\n",
    "- CPI2010 = 2010 [World Bank Consumer Price Index](https://data.worldbank.org/indicator/FP.CPI.TOTL) for country of interest.\n",
    "- CPI2022 = 2022 Consumer Price Index for country of interest (latest value).\n",
    "- In calculating maximum damage, first array value is 2010 building reconstruction costs per square meter.\n",
    "- Second array value is 2010 building content replacement value per square meter.\n",
    "\n",
    "Damage classes:\n",
    "- Options are Residential, Commercial, Industrial, Agriculture, Cultural, and Transportation, as well as an Universal class.\n",
    "- In the default code, Agriculture, Cultural, and Transportation as well as unclassified buildings are set to Universal.\n",
    "\n",
    "Damage function:\n",
    "- Based on polynomial functions fit to the JRC depth-damage curves, with the order depending on fit (coefs).\n",
    "- In the default code, a combined damage function is applied based on Residential, Commercial, and Industrial JRC depth-damage values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da60020-56c9-41a5-a817-c80f617efd49",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "0da60020-56c9-41a5-a817-c80f617efd49",
    "outputId": "2855d3d2-0ec1-486c-9bfa-10b7f313e2b0"
   },
   "outputs": [],
   "source": [
    "# Define arrays for damage values based on 2010 estimates \n",
    "CPI2010 = 100                                  # 2010 EU Consumer Price Index Value\n",
    "CPI2022 = 121.8                                # 2022 EU Consumer Price Index Value\n",
    "CPI_Frac = CPI2022 / CPI2010\n",
    "MaxDmgRES = np.array([480, 240]) * CPI_Frac    # EU Value, Residential\n",
    "MaxDmgCOM = np.array([502, 502]) * CPI_Frac    # EU Value, Commercial\n",
    "MaxDmgIND = np.array([328, 492]) * CPI_Frac    # EU Value, Industrial\n",
    "MaxDmgAGR = np.array([0.23, 0.46]) * CPI_Frac  # Italy 2021 (AGR), Agricultural, currently not used\n",
    "MaxDmgCUL = MaxDmgCOM                          # EU Value, Cultural, currently not used\n",
    "MaxDmgTRS = MaxDmgIND                          # Italy 2021 (TRS), Transport, currently not used\n",
    "MaxDmgUNI = (MaxDmgRES+MaxDmgCOM+MaxDmgIND)/3  # Universal class\n",
    "# Combine damage arrays into a single array\n",
    "MaxDmg = np.column_stack((MaxDmgRES, MaxDmgCOM, MaxDmgIND, MaxDmgUNI))\n",
    "\n",
    "# Damage classes\n",
    "DamageClasses = ['Residential', 'Commercial', 'Industrial','Universal']\n",
    "\n",
    "def DamageFunction(wd1, coefs, wd_range=(0, 6)):\n",
    "    wd = np.clip(wd1, *wd_range)\n",
    "    y = coefs[0] * wd**5 + coefs[1] * wd**4 + coefs[2] * wd**3 \\\n",
    "        + coefs[3] * wd**2 + coefs[4] * wd + coefs[5]\n",
    "    y = np.clip(y, 0, 1)\n",
    "    return y\n",
    "\n",
    "# Polynomial coefficients for each function\n",
    "#   - Up to 5th order\n",
    "#   - 1st value is highest order (5th) and last is intercept\n",
    "coefs_UNI = [0.0,  0.0, 0.0, -0.02787, 0.3334, 0.0]\n",
    "coefs_RES = [0.0005869, -0.01077, 0.07497, -0.2602, 0.5959, 0.0]\n",
    "coefs_COM = [0.0, 0.0, -0.0009149, -0.02021, 0.3216, 0.0]\n",
    "coefs_IND = [0.0, 0.0, -0.001202, -0.01225, 0.2852, 0.0]\n",
    "coefs_TRS = [0.0, -0.00938, 0.07734, -0.2906, 0.7625, 0.0]\n",
    "coefs_AGR = [0.0, -0.004601, 0.06114, -0.3061, 0.7773, 0.0]\n",
    "\n",
    "# Plot Depth Damage Functions\n",
    "# Water depth values from 0 to 6m\n",
    "wd_values = np.linspace(0, 6, 100)\n",
    "dmgRES = DamageFunction(wd_values, coefs_RES)\n",
    "dmgCOM = DamageFunction(wd_values, coefs_COM)\n",
    "dmgIND = DamageFunction(wd_values, coefs_IND)\n",
    "dmgUNI = DamageFunction(wd_values, coefs_UNI)\n",
    "if flagDamageCurve is True:\n",
    "    plt.plot(wd_values, dmgUNI, color='black', linewidth=2, label='Universal')\n",
    "    plt.plot(wd_values, dmgRES, color='darkgreen', linestyle='--', linewidth=1,\n",
    "            label='Residential')\n",
    "    plt.plot(wd_values, dmgCOM, color='blue', linestyle='--', linewidth=1,\n",
    "            label='Commercial')\n",
    "    plt.plot(wd_values, dmgIND, color='darkred', linestyle='--', linewidth=1,\n",
    "            label='Industrial')\n",
    "    plt.grid(color='grey', linestyle='-', linewidth=0.5)\n",
    "    plt.xlabel('Water Depth (m)')\n",
    "    plt.ylabel('Damage Fraction')\n",
    "    plt.title('JRC Residential, Commercial & Industrial Depth-Damage Functions')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cc46ba-267b-48c4-af6d-2653ac3fc0e1",
   "metadata": {
    "id": "86cc46ba-267b-48c4-af6d-2653ac3fc0e1"
   },
   "source": [
    "## Retrieving data for the area of interest\n",
    "In this section the bounding box is used to crop the data to the area of interest.\n",
    "The code converts latitude and longitude values to the equivalent projection used by the flood map raster & writes bounding box to shapefile. We also define the bounding box for OpenStreetMap data.\n",
    "\n",
    "If the region of interest is not as desired, the latitude and longitude values can be changed in the \"Define inputs\" section above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad25199",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set shape box location\n",
    "shpBBox = os.path.join(dirOSM, f'outline_{saveName}.shp')\n",
    "\n",
    "# Determine Raster EPSG Code (only works with osgeo)\n",
    "ds = gdal.Open(rastDepths)\n",
    "srs = osr.SpatialReference()\n",
    "srs.ImportFromWkt(ds.GetProjection())\n",
    "epsgRast = f'EPSG:{srs.GetAuthorityCode(None)}'\n",
    "ds = None\n",
    "\n",
    "print(f'Water Depth Raster Projection: {epsgRast}')\n",
    "\n",
    "# Create a transformer for coordinate conversion\n",
    "transformer = Transformer.from_crs('EPSG:4326', epsgRast, always_xy=True)\n",
    "\n",
    "# Convert bounding box coordinates to raster CRS\n",
    "xMin, yMin = transformer.transform(Longitude1-xbuffer, Latitude1-ybuffer)\n",
    "xMax, yMax = transformer.transform(Longitude2+xbuffer, Latitude2+ybuffer)\n",
    "\n",
    "print('Converted Coordinate Bounds with Buffer:')\n",
    "print(f'  Longitudes: {Longitude1-xbuffer}E --> {xMin} meters & {Longitude2+xbuffer}E --> {xMax} meters')\n",
    "print(f'  Latitudes: {Latitude1-ybuffer}N --> {yMin} meters & {Latitude2+ybuffer}N --> {yMax} meters')\n",
    "\n",
    "# Define the bounding box coordinates based on the zoomed region\n",
    "bounding_box = gpd.GeoDataFrame(geometry=outlineGeometry)\n",
    "# Write the GeoDataFrame to a shapefile\n",
    "bounding_box.to_file(shpBBox)\n",
    "print('Bounding Box Shapefile written to: '+shpBBox)\n",
    "\n",
    "# Read GeoDataFrame from the bounding box shapefile\n",
    "gdfBBox = gpd.read_file(shpBBox)\n",
    "crsRast = gdfBBox.crs\n",
    "\n",
    "for RP in ImageReturnPeriod:\n",
    "    rastDepths = os.path.join(dirDepths, f'Europe_RP{RP}_filled_depth.tif')\n",
    "    # Read the raster using rasterio\n",
    "    with rasterio.open(rastDepths) as src:\n",
    "        window = from_bounds(xMin, yMin, xMax, yMax, src.transform)\n",
    "        rDepths = src.read(1, window=window)\n",
    "        rDepths = np.ma.masked_where((rDepths < -999) | (rDepths > 1000), rDepths)\n",
    "        max_depth  = rDepths.max()\n",
    "        if customMaxDepthLegend == -1:\n",
    "            maxDepthLegend = ((max_depth // 1) + 1)\n",
    "        else:\n",
    "            maxDepthLegend=customMaxDepthLegend\n",
    "        missing_data_value = src.nodata\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(rDepths, vmin=0, vmax=maxDepthLegend, cmap=cmap_h2o, extent=(xMin, xMax, yMin, yMax),\n",
    "                zorder=2, alpha=0.7)\n",
    "    plt.title(f'River flood map with {RP}-year return period')\n",
    "    plt.xlabel('Longitude', fontsize='small')\n",
    "    plt.ylabel('Latitude', fontsize='small')\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "    plt.colorbar(im, cax=cax,label='Depth (m)',extend='max')\n",
    "    plt.text(.02,.02,f'Projection in {epsgRast}', fontsize=8,\n",
    "             path_effects=[pe.withStroke(linewidth=3, foreground=\"white\")], transform=ax.transAxes,zorder=7)\n",
    "    ax.set_xlim(Longitude1-xbuffer,Longitude2+xbuffer)\n",
    "    ax.set_ylim(Latitude1-ybuffer,Latitude2+ybuffer)\n",
    "    ctx.add_basemap(ax=ax, crs=epsgRast, source=ctx.providers.OpenStreetMap.Mapnik, attribution_size='6', alpha=0.5)\n",
    "    txt = ax.texts[-1]\n",
    "    txt.set_position([0.99,0.98])\n",
    "    txt.set_ha('right')\n",
    "    txt.set_va('top')\n",
    "    if showOutlineFlag is True:\n",
    "        outlineGeometry.plot(ax=ax, edgecolor=outlineColour, linestyle=outlineStyle, linewidth=outlineThickness, facecolor=outlineFace, alpha=outlineAlpha, zorder=5)\n",
    "    if outlineLabelFlag is True:\n",
    "        outline_legend = mlines.Line2D([], [], color=outlineColour, linewidth=outlineThickness, label=outlineLabel)\n",
    "        legend_outline=ax.legend(handles=[outline_legend], loc=outlineLabelPosition, fontsize=outlineLabelSize, frameon=True)\n",
    "    if imageSaveFlag is True:\n",
    "        plt.savefig(os.path.join(dirImages, f'{saveName}_floodmap_{RP}RP.png'), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "##--------------------------------------------------------\n",
    "## Population map\n",
    "# Open the raster file\n",
    "ds = gdal.Open(rastPopulation)\n",
    "if ds is None:\n",
    "    raise RuntimeError(f\"Failed to open the raster file: {rastPopulation}\")\n",
    "\n",
    "# Get the projection from the raster file\n",
    "proj_wkt = ds.GetProjection()\n",
    "srs = osr.SpatialReference()\n",
    "srs.ImportFromWkt(proj_wkt)\n",
    "\n",
    "# Try to get the EPSG code\n",
    "epsg_code = srs.GetAuthorityCode(None)\n",
    "\n",
    "# Check if the EPSG code was successfully retrieved\n",
    "if epsg_code is None:\n",
    "    # If not, you might need to handle specific cases manually\n",
    "    # Check if the projection matches known projections\n",
    "    proj4_str = srs.ExportToProj4()\n",
    "    if '+proj=moll' in proj4_str and '+datum=WGS84' in proj4_str:\n",
    "        epsg_code = 'EPSG:54009'  # ESRI:54009 World Mollweide projection\n",
    "    else:\n",
    "        raise RuntimeError(\"Unable to determine EPSG code for the given projection.\")\n",
    "else:\n",
    "    epsg_code = f\"EPSG:{epsg_code}\"\n",
    "\n",
    "epsgRastPop = epsg_code\n",
    "# Close the dataset\n",
    "ds = None\n",
    "print(f'Population Raster Projection: {epsgRastPop}')\n",
    "\n",
    "# Create a transformer for coordinate conversion\n",
    "if epsg_code == 'EPSG:54009':\n",
    "    PopProj = '+proj=moll +datum=WGS84 +units=m' #MOLLWEIDE HAS TO BE MANUALLY INSERTED\n",
    "else:\n",
    "    PopProj = epsg_code\n",
    "\n",
    "transformer = Transformer.from_crs('EPSG:4326', PopProj, always_xy=True)\n",
    "\n",
    "# Convert bounding box coordinates to raster CRS\n",
    "xMinPop, yMinPop = transformer.transform(Longitude1-xbuffer, Latitude1-ybuffer)\n",
    "xMaxPop, yMaxPop = transformer.transform(Longitude2+xbuffer, Latitude2+ybuffer)\n",
    "\n",
    "# Ensure xMin < xMax and yMin < yMax\n",
    "xMinPop, xMaxPop = min(xMinPop, xMaxPop), max(xMinPop, xMaxPop)\n",
    "yMinPop, yMaxPop = min(yMinPop, yMaxPop), max(yMinPop, yMaxPop)\n",
    "\n",
    "print('Converted Coordinate Bounds with Buffer:')\n",
    "print(f'  Longitudes: {Longitude1-xbuffer}E --> {xMinPop} meters & {Longitude2+xbuffer}E --> {xMaxPop} meters')\n",
    "print(f'  Latitudes: {Latitude1-ybuffer}N --> {yMinPop} meters & {Latitude2+ybuffer}N --> {yMaxPop} meters')\n",
    "\n",
    "# Read the raster using rasterio\n",
    "with rasterio.open(rastPopulation) as src:\n",
    "    window = from_bounds(xMinPop, yMinPop, xMaxPop, yMaxPop, src.transform)\n",
    "    rPopulation = src.read(1, window=window)\n",
    "    rPopulation = np.ma.masked_where((rPopulation < 0.1), rPopulation)\n",
    "    max_population = rPopulation.max()\n",
    "    maxPopLegend = ((max_population // 100) + 1) * 100\n",
    "    missing_data_value = src.nodata\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(rPopulation, vmin=0, vmax=maxPopLegend, cmap=cmap_pop, extent=(xMinPop, xMaxPop, yMinPop, yMaxPop),\n",
    "               zorder=2, alpha=0.7)\n",
    "plt.title(f'Population Raster for the year {PopYear}')\n",
    "plt.xlabel('Longitude', fontsize='small')\n",
    "plt.ylabel('Latitude', fontsize='small')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "plt.colorbar(im, cax=cax, label='People per 3 arcseconds\\u00B2', extend='max')\n",
    "plt.text(.02,.02,f'Projection in {epsgRastPop}', fontsize=8,\n",
    "             path_effects=[pe.withStroke(linewidth=3, foreground=\"white\")], transform=ax.transAxes,zorder=7)\n",
    "ax.set_xlim(Longitude1-xbuffer,Longitude2+xbuffer)\n",
    "ax.set_ylim(Latitude1-ybuffer,Latitude2+ybuffer)\n",
    "ctx.add_basemap(ax=ax, crs=epsgRastPop, source=ctx.providers.OpenStreetMap.Mapnik, attribution_size='6', alpha=1)\n",
    "txt = ax.texts[-1]\n",
    "txt.set_position([0.99,0.98])\n",
    "txt.set_ha('right')\n",
    "txt.set_va('top')\n",
    "if showOutlineFlag is True:\n",
    "    outlineGeometry.plot(ax=ax, edgecolor=outlineColour, linestyle=outlineStyle, linewidth=outlineThickness, facecolor=outlineFace, alpha=outlineAlpha, zorder=5)\n",
    "if outlineLabelFlag is True:\n",
    "    outline_legend = mlines.Line2D([], [], color=outlineColour, linewidth=outlineThickness, label=outlineLabel)\n",
    "    legend_outline=ax.legend(handles=[outline_legend], loc=outlineLabelPosition, fontsize=outlineLabelSize, frameon=True)\n",
    "if imageSaveFlag is True:\n",
    "    plt.savefig(os.path.join(dirImages, f'{saveName}_populationmap_{PopYear}.png'), bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f8d715-7eb2-44bc-8a8e-09278fe2aad2",
   "metadata": {
    "id": "57f8d715-7eb2-44bc-8a8e-09278fe2aad2"
   },
   "source": [
    "### OpenStreetMap buildings data\n",
    "In this section the OSM data are loaded based on the bounding box defined above. The extracted data represents the building use (unclassified) and is written to a shapefile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520f6a84-2086-458d-b64b-51b0d7ea27eb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "520f6a84-2086-458d-b64b-51b0d7ea27eb",
    "outputId": "2346f484-9af5-42e3-ee56-428e95d48bfc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Output shapefile for unclassified buildings\n",
    "shpOSM = os.path.join(dirOSM, f'{saveName}_OSM_Building_Unclassified.shp')\n",
    "\n",
    "# Define tags for OSM data\n",
    "tags = {'building': True,'amenity': True}\n",
    "# Retrieve OSM geometries within the bounding box\n",
    "gdfOSM = ox.features_from_polygon(outlineGeometry.iloc[0], tags)\n",
    "# Filter out non-Polygon geometries\n",
    "gdfOSM = gdfOSM[gdfOSM.geom_type == 'Polygon']\n",
    "# Confirm that all of the GDF elements are compatible with shp format\n",
    "gdfOSM = gdfOSM.map(lambda x: str(x) if isinstance(x, list) else x)\n",
    "# Clip the OSM data to the bounding box\n",
    "gdfOSM = gpd.clip(gdfOSM, outlineGeometry)\n",
    "# Save the polygon-only gdp to shapefile\n",
    "warnings.simplefilter(\"ignore\",category=UserWarning) #Removing UserWarning regarding truncated columns when saving to ESRI Shapefile\n",
    "gdfOSM.to_file(shpOSM, driver='ESRI Shapefile', encoding='utf-8')\n",
    "warnings.resetwarnings()\n",
    "print('OSM data read in and saved to shapefile')\n",
    "print('  '+shpOSM)\n",
    "\n",
    "if flagBuilding is True:\n",
    "    # Plot data\n",
    "    fig, ax = plt.subplots()  # Adjust figsize as needed\n",
    "    plt.title('OSM Buildings: Prior to residential, commericial and industrial classification')\n",
    "    plt.xlabel('Longitude', fontsize='small')\n",
    "    plt.ylabel('Latitude', fontsize='small')\n",
    "    plt.text(.02,.02,f'Projection in {gdfOSM.crs}', fontsize=8,\n",
    "              path_effects=[pe.withStroke(linewidth=3, foreground=\"white\")], transform=ax.transAxes,zorder=7)\n",
    "    if showOutlineFlag is True:\n",
    "        outlineGeometry.plot(ax=ax, edgecolor=outlineColour, linestyle=outlineStyle, linewidth=outlineThickness, facecolor=outlineFace, alpha=outlineAlpha, zorder=5)\n",
    "    if outlineLabelFlag is True:\n",
    "        outline_legend = mlines.Line2D([], [], color=outlineColour, linewidth=outlineThickness, label=outlineLabel)\n",
    "        legend_outline=ax.legend(handles=[outline_legend], loc=outlineLabelPosition, fontsize=outlineLabelSize, frameon=True)\n",
    "    gdfOSM.plot(column='building',ax=ax, legend=True, cmap='coolwarm',\n",
    "                      legend_kwds={'ncol': 3, 'bbox_to_anchor': (.5, -0.15), 'loc': 'upper center', 'title': 'Building Legend:'})\n",
    "    ax.set_xlim(Longitude1-xbuffer,Longitude2+xbuffer)\n",
    "    ax.set_ylim(Latitude1-ybuffer,Latitude2+ybuffer)\n",
    "    ctx.add_basemap(ax=ax, crs=gdfOSM.crs, source=ctx.providers.OpenStreetMap.Mapnik, attribution_size='6', alpha=0.5)\n",
    "    txt = ax.texts[-1]\n",
    "    txt.set_position([0.99,0.98])\n",
    "    txt.set_ha('right')\n",
    "    txt.set_va('top')\n",
    "    if outlineLabelFlag is True:\n",
    "        ax.add_artist(legend_outline)\n",
    "    if imageSaveFlag is True:\n",
    "        plt.savefig(os.path.join(dirImages, f'{saveName}_OSMbuilding_preclassification.png'), bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd15112-c1da-4046-a726-cc91fb5c3cfa",
   "metadata": {
    "id": "efd15112-c1da-4046-a726-cc91fb5c3cfa"
   },
   "source": [
    "### Reproject OSM data to raster projection\n",
    "In this section, in order to perform the damage analysis, the OSM and raster data need to be on the same Coordinate Reference System (CRS). The OSM are on an EPSG:4326 CRS and the raster data could be another.  In the cell, the OSM data are converted to match the raster CRS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6646a7b8-dba6-4a92-ab98-53a9a2fac2e8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6646a7b8-dba6-4a92-ab98-53a9a2fac2e8",
    "outputId": "56d602ee-469c-4fb9-a4e7-43cd3b6130f2"
   },
   "outputs": [],
   "source": [
    "# Determine CRSs from shapefile and Raster\n",
    "crsOSM = gdfOSM.crs\n",
    "\n",
    "if crsOSM not in (epsgRast, epsgRast.lower()):\n",
    "    print(f'Reprojecting from OSM {crsOSM} to raster EPSG:{epsgRast}')\n",
    "    # Read the GeoDataFrame if reprojection is needed\n",
    "    gdfOSM = gpd.read_file(shpOSM)\n",
    "    # Reproject the GeoDataFrame to match the raster CRS\n",
    "    gdfOSM = gdfOSM.to_crs(epsg=epsgRast)\n",
    "    # Save the reprojected data back to the shapefile\n",
    "    gdfOSM.to_file(shpOSM)\n",
    "    print('  Overwriting reprojected data:', shpOSM)\n",
    "\n",
    "else:\n",
    "    print('No reprojection performed. Both projections are the same:', crsOSM)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f096a30-878d-4573-a7cf-241a1400d378",
   "metadata": {
    "id": "7f096a30-878d-4573-a7cf-241a1400d378"
   },
   "source": [
    "### Building classifications\n",
    "In this section, the building types are classified to Residential, Commercial, Industrial, etc.\n",
    "- This procedure needs to be performed manually by looking at the list of building types.\n",
    "- If None is listed for a building class (bldgClass column), the building type (building column) should be assigned to one of the lists (e.g., classResidential, classCommercial, classIndustrial).\n",
    "- Buildings with type \"yes\" will be classified as Universal by default in a later step.\n",
    "\n",
    "As calculated in an earlier section, the Universal class has a damage curve equal to the average of the Residential, Commercial, and Industrial ones.\n",
    "\n",
    "Below we have added a classification of OSM building types already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a03ac01-914b-4ebf-84b4-489785e9e653",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6a03ac01-914b-4ebf-84b4-489785e9e653",
    "outputId": "b0134344-eec7-4cda-bdb6-5c1a9c2894ca"
   },
   "outputs": [],
   "source": [
    "# CSV file with classifications (classResidential, classCommercial, etc)\n",
    "csvOSMclasses = os.path.join(dirOSM, f'{saveName}_OSM_Building_Reclassified.csv')\n",
    "csvOSMamenity = os.path.join(dirOSM, f'{saveName}_OSM_Amenity_Classified.csv')\n",
    " # Keep only the building and geometry columns\n",
    "gdfBuildings = gdfOSM[['building','amenity','geometry']].copy()\n",
    "\n",
    "# Building classifications\n",
    "#   - Change and add as needed \n",
    "classResidential = ['hut', 'apartments', 'detached', 'residential', 'house', 'barn', 'garage',\n",
    "                    'carport', 'semidetached_house', 'shed', 'bungalow', 'roof', 'terrace',\n",
    "                    'allotment_house']\n",
    "classCommercial = ['commercial', 'office', 'retail', 'kiosk', 'supermarket', 'warehouse',\n",
    "                   'garages', 'hotel', 'stadium', 'grandstand', 'sports_centre',  'pavilion',\n",
    "                   'government', 'school', 'kindergarten', 'university', 'dormitory', 'public',\n",
    "                   'service', 'hospital', 'civic', 'terminal', 'fire_station',\n",
    "                   'train_station', 'boathouse', 'toilets', 'tech_cab', 'tower', 'portal',\n",
    "                   'columbarium', 'greenhouse', 'guardhouse', 'construction',\n",
    "                   'funeral_hall']\n",
    "classIndustrial = ['industrial', 'manufacture']\n",
    "classCultural = ['church', 'cathedral', 'baptistery', 'obelisk', 'basilica', 'monastery', 'ruins',\n",
    "                 'column', 'chapel', 'synagogue', 'shrine', 'religious', 'convent', 'fort']\n",
    "classAgricultural = ['farm_auxiliary']\n",
    "classTransportation = ['bridge', 'parking']\n",
    "classUniversal = ['universal']\n",
    "\n",
    "# Critical infrastructure, add infrastructure of interest ------- \n",
    "#   - Change and add as needed, NB: Can classify critical infrastructure both through it's building or amenity tag.\n",
    "#   - It is suggested to run this cell once, read the output below, and add the building or amenities required in the critical infrastructure list\n",
    "criticalInfrastructureList = ['hospital','fuel','bank','clinic','pharmacy', \n",
    "                             'police','prison','refugee_site', \n",
    "                             'train_station',\n",
    "                             'fire_station','transformer_tower','water_tower','bridge',\n",
    "                             'transportation']\n",
    "# This affects the look of the maps in the 'Critical Infrastructure' section\n",
    "critMarkersColours = {\n",
    "    'hospital': {'marker': 'P', 'color': 'red'}, \n",
    "    'police': {'marker': 's', 'color': 'blue'}, \n",
    "    'train_station': {'marker': 'o', 'color': 'green'}, \n",
    "    'transformer_tower': {'marker': '*', 'color': 'purple'}, \n",
    "    'water_tower': {'marker': 'v', 'color': 'orange'}, \n",
    "    'bridge': {'marker': 'd', 'color': 'brown'}, \n",
    "    'fire_station': {'marker': 'X', 'color': 'pink'}, \n",
    "    'transportation': {'marker': '>', 'color': 'cyan'}, \n",
    "    'refugee_site': {'marker': 'o', 'color': 'lime'},\n",
    "    'fuel': {'marker': '2', 'color': 'yellow'},\n",
    "}  \n",
    "    #Here are some more example of marker and colours in case they are needed. Feel free to experiment:\n",
    "    #OtherMarkerList=['^','p','D','H','X','h']; OtherColourList=['lime','darkgreen','navy','slategray','pink','magenta']\n",
    "\n",
    "# For now, set transportation and cultural to universal (can add/change if desired)\n",
    "classUniversal = classUniversal + classCultural + classAgricultural + classTransportation\n",
    "classCultural = []\n",
    "classAgricultural = []\n",
    "classTransportation = []\n",
    "\n",
    "# Convert building classes to dataframe\n",
    "bldgClasses = pd.DataFrame({'building': gdfBuildings['building'].unique()})\n",
    "\n",
    "# Classify each structure to Residential, Commercial, Industrial, etc.\n",
    "#   - Structures not listed in above class lists are classified as none\n",
    "bldgClasses['bldgClass'] = None\n",
    "bldgClasses.loc[bldgClasses['building'].isin(classResidential), 'bldgClass'] = 'Residential'\n",
    "bldgClasses.loc[bldgClasses['building'].isin(classCommercial), 'bldgClass'] = 'Commercial'\n",
    "bldgClasses.loc[bldgClasses['building'].isin(classIndustrial), 'bldgClass'] = 'Industrial'\n",
    "bldgClasses.loc[bldgClasses['building'].isin(classCultural), 'bldgClass'] = 'Cultural'\n",
    "bldgClasses.loc[bldgClasses['building'].isin(classAgricultural), 'bldgClass'] = 'Agricultural'\n",
    "bldgClasses.loc[bldgClasses['building'].isin(classTransportation), 'bldgClass'] = 'Transportation'\n",
    "bldgClasses.loc[bldgClasses['building'].isin(classUniversal), 'bldgClass'] = 'Universal'\n",
    "\n",
    "#   - Adding critical infrastructure\n",
    "bldgClasses['critInfrastructure'] = None\n",
    "bldgClasses.loc[bldgClasses['building'].isin(criticalInfrastructureList), 'critInfrastructure'] = True\n",
    "\n",
    "amenityClasses = pd.DataFrame({'amenity': gdfBuildings['amenity'].unique()})\n",
    "amenityClasses['critInfrastructure'] = None\n",
    "amenityClasses.loc[amenityClasses['amenity'].isin(criticalInfrastructureList), 'critInfrastructure'] = True\n",
    "\n",
    "\n",
    "# Write structure and classification to CSV\n",
    "bldgClasses.to_csv(csvOSMclasses, index=False)\n",
    "amenityClasses.to_csv(csvOSMamenity, index=False)\n",
    "\n",
    "print('Building Classifications')\n",
    "print('  - If None is listed for a building class, add the building one of the above lists.')\n",
    "print(\"  - Building 'yes' will be classified as Universal in a later step.\")\n",
    "print(bldgClasses)\n",
    "print(amenityClasses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179bd14e-2f54-4479-a485-6f91b9b18216",
   "metadata": {
    "id": "179bd14e-2f54-4479-a485-6f91b9b18216"
   },
   "source": [
    "In the code below, the building types are classified and written to a ShapeFile with a column.\n",
    "- The first map shows the buildings that have been classified based on the above assignments.\n",
    "- The second map shows the same, but the with building type \"yes\" classified as Universal. The difference between the maps provides an idea of the how many building have a type assigned to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e3d6dd-db48-4009-9b17-f77f05bbf042",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "a7e3d6dd-db48-4009-9b17-f77f05bbf042",
    "outputId": "0f74a22d-c3ed-41c9-e6c1-50b8855a6723",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Shapefile name with reclassied buildings (output)\n",
    "shpOSMreclass = os.path.join(dirOSM,f'{saveName}_OSM_Building_Reclassified.shp')\n",
    "\n",
    "# Building classification created earlier\n",
    "bldgClasses = pd.read_csv(csvOSMclasses)\n",
    "\n",
    "# Merge the spatial data with the new information\n",
    "gdfOSMreclass = pd.merge(gdfOSM, bldgClasses, on='building', how='left')\n",
    "\n",
    "if flagBuilding is True:\n",
    "    # Plot without unclassified buildings\n",
    "    fig, ax = plt.subplots()  # Adjust figsize as needed\n",
    "    plt.title('Building Data without Unclassified Buildings')\n",
    "    plt.xlabel('Longitude', fontsize='small')\n",
    "    plt.ylabel('Latitude', fontsize='small')\n",
    "    plt.text(.02,.02,f'Projection in {gdfOSM.crs}', fontsize=8,\n",
    "                path_effects=[pe.withStroke(linewidth=3, foreground=\"white\")], transform=ax.transAxes,zorder=7)\n",
    "    if showOutlineFlag is True:\n",
    "        outlineGeometry.plot(ax=ax, edgecolor=outlineColour, linestyle=outlineStyle, linewidth=outlineThickness, facecolor=outlineFace, alpha=outlineAlpha, zorder=5)\n",
    "    if outlineLabelFlag is True:\n",
    "        outline_legend = mlines.Line2D([], [], color=outlineColour, linewidth=outlineThickness, label=outlineLabel)\n",
    "        legend_outline=ax.legend(handles=[outline_legend], loc=outlineLabelPosition, fontsize=outlineLabelSize, frameon=True)\n",
    "    gdfOSMreclass.plot(column='bldgClass', ax=ax, legend=True, cmap=cmap_cls,\n",
    "                       legend_kwds={'ncol': 4, 'bbox_to_anchor': (.5, -0.15), 'loc': 'upper center', 'title': 'Building Classes:'})\n",
    "    ax.set_xlim(Longitude1-xbuffer,Longitude2+xbuffer)\n",
    "    ax.set_ylim(Latitude1-ybuffer,Latitude2+ybuffer)\n",
    "    ctx.add_basemap(ax=ax, crs=gdfOSM.crs, source=ctx.providers.OpenStreetMap.Mapnik, attribution_size='6', alpha=0.5)\n",
    "    txt = ax.texts[-1]\n",
    "    txt.set_position([0.99,0.98])\n",
    "    txt.set_ha('right')\n",
    "    txt.set_va('top')\n",
    "    if outlineLabelFlag is True:\n",
    "        ax.add_artist(legend_outline)\n",
    "    if imageSaveFlag is True:\n",
    "        plt.savefig(os.path.join(dirImages, f'{saveName}_OSMbuilding_unclassified_simple.png'), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Substitute undefined (null) building classes\n",
    "gdfOSMreclass['bldgClass'] = gdfOSMreclass['bldgClass'].fillna('Universal')\n",
    "\n",
    "# Write classified structures to file\n",
    "warnings.simplefilter(\"ignore\",category=UserWarning) #Removing UserWarning regarding truncated columns when saving to ESRI Shapefile\n",
    "gdfOSMreclass.to_file(shpOSMreclass, encoding='utf-8')\n",
    "warnings.resetwarnings()\n",
    "\n",
    "if flagBuilding is True:\n",
    "    # Plot with unclassified buildings as classified\n",
    "    fig, ax = plt.subplots()  # Adjust figsize as needed\n",
    "    plt.title('Building Data with Unclassified Buildings as Universal Class')\n",
    "    plt.xlabel('Longitude', fontsize='small')\n",
    "    plt.ylabel('Latitude', fontsize='small')\n",
    "    plt.text(.02,.02,f'Projection in {gdfOSM.crs}', fontsize=8,\n",
    "                path_effects=[pe.withStroke(linewidth=3, foreground=\"white\")], transform=ax.transAxes,zorder=7)\n",
    "    if showOutlineFlag is True:\n",
    "        outlineGeometry.plot(ax=ax, edgecolor=outlineColour, linestyle=outlineStyle, linewidth=outlineThickness, facecolor=outlineFace, alpha=outlineAlpha, zorder=5)\n",
    "    if outlineLabelFlag is True:\n",
    "        outline_legend = mlines.Line2D([], [], color=outlineColour, linewidth=outlineThickness, label=outlineLabel)\n",
    "        legend_outline=ax.legend(handles=[outline_legend], loc=outlineLabelPosition, fontsize=outlineLabelSize, frameon=True)\n",
    "    gdfOSMreclass.plot(column='bldgClass', ax=ax, legend=True, cmap=cmap_cls,\n",
    "                       legend_kwds={'ncol': 4, 'bbox_to_anchor': (.5, -0.15), 'loc': 'upper center', 'title': 'Building Classes:'})\n",
    "    ax.set_xlim(Longitude1-xbuffer,Longitude2+xbuffer)\n",
    "    ax.set_ylim(Latitude1-ybuffer,Latitude2+ybuffer)\n",
    "    ctx.add_basemap(ax=ax, crs=gdfOSM.crs, source=ctx.providers.OpenStreetMap.Mapnik, attribution_size='6', alpha=0.5)\n",
    "    txt = ax.texts[-1]\n",
    "    txt.set_position([0.99,0.98])\n",
    "    txt.set_ha('right')\n",
    "    txt.set_va('top')\n",
    "    if outlineLabelFlag is True:\n",
    "        ax.add_artist(legend_outline)\n",
    "    if imageSaveFlag is True:\n",
    "        plt.savefig(os.path.join(dirImages, f'{saveName}_OSMbuilding_classified_simple.png'), bbox_inches='tight')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc143ea3-daab-4c6b-ae22-6b917a4f0a1e",
   "metadata": {
    "id": "fc143ea3-daab-4c6b-ae22-6b917a4f0a1e"
   },
   "source": [
    "## Flood depths at building locations\n",
    "In this section, the flood map rasters for each return period (extreme event) are loaded.\n",
    "- The rasters are then translated to flood depths for each building based on the desired statistic (mean, maximum or minimum depth or all three).\n",
    "- For each return period a plot of a flood map can be generated as well as a plot with the flood depths corresponding to each building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36614b5-eaf6-47c9-bc91-ce30a16337bc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "a36614b5-eaf6-47c9-bc91-ce30a16337bc",
    "outputId": "db29e4d3-65c8-46b2-d02c-2413b817ba6b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for RP in ReturnPeriods:\n",
    "\n",
    "    print(\"Computing Building Water Depths:  RP=\", str(RP))\n",
    "    print('  Loading water depth for selected bounds:  RP=', str(RP))\n",
    "    rastDepths = os.path.join(dirDepths, f'Europe_RP{RP}_filled_depth.tif')\n",
    "    rastDepths_zoom = rastDepths.replace('Europe', f'{saveName}_Europe')\n",
    "    print(f'  {rastDepths}')\n",
    "\n",
    "    # Keep only the building, bldgClass and geometry columns\n",
    "\n",
    "    gdfDamage = gdfOSMreclass[['building', 'bldgClass', 'geometry']].copy()\n",
    "\n",
    "    # Compute building areas in m2\n",
    "    gdfDamage_ESPG3035=gdfDamage.to_crs(3035)\n",
    "    gdfDamage['Area_m2'] = gdfDamage_ESPG3035.geometry.area\n",
    "\n",
    "    # Read the raster using rasterio\n",
    "    with rasterio.open(rastDepths) as src:\n",
    "        rDepths, out_transform = mask(src, outlineGeometry, crop=True)\n",
    "        rDepths = rDepths[0]\n",
    "        rDepths = np.ma.masked_where((rDepths < -999) | (rDepths > 1000), rDepths)\n",
    "        missing_data_value = src.nodata\n",
    "        max_depth  = rDepths.max()\n",
    "        with rasterio.open(\n",
    "            rastDepths_zoom,\n",
    "            'w',\n",
    "            driver='GTiff',\n",
    "            height=rDepths.shape[0],\n",
    "            width=rDepths.shape[1],\n",
    "            count=1,\n",
    "            dtype=rDepths.dtype,\n",
    "            crs=src.crs,\n",
    "            transform=out_transform,\n",
    "            nodata=missing_data_value\n",
    "        ) as dst:\n",
    "            dst.write(rDepths, 1)\n",
    "    height, width = rDepths.shape\n",
    "    xMinDepth, yMinDepth, xMaxDepth, yMaxDepth = array_bounds(height, width, out_transform)    \n",
    "    # Perform zonal statistics directly on the raster array        \n",
    "    result = rasterstats.zonal_stats(\n",
    "        gdfDamage,\n",
    "        rDepths,\n",
    "        nodata=src.nodata,\n",
    "        affine=out_transform,\n",
    "        stats=['mean', 'min', 'max'],\n",
    "        all_touched=True\n",
    "    )\n",
    "\n",
    "    # Update geodataframe with zonal statistics\n",
    "    gdfDamage[\"MeanDepth\"] = [entry[\"mean\"] for entry in result]\n",
    "    gdfDamage[\"MinDepth\"] = [entry[\"min\"] for entry in result]\n",
    "    gdfDamage[\"MaxDepth\"] = [entry[\"max\"] for entry in result]\n",
    "\n",
    "    if customMaxDepthLegend == -1:\n",
    "        maxDepthLegend = ((max_depth // 1) + 1)\n",
    "    else:\n",
    "        maxDepthLegend=customMaxDepthLegend\n",
    "\n",
    "    if RP in ImageReturnPeriod and flagBuildingH2o is True:\n",
    "        fig, ax = plt.subplots()\n",
    "        plt.title(f'Buildings map and river flood map with {RP}-year return period')\n",
    "        plt.xlabel('Longitude', fontsize='small')\n",
    "        plt.ylabel('Latitude', fontsize='small')\n",
    "        im = ax.imshow(rDepths, vmin=0, vmax=maxDepthLegend, cmap=cmap_h2o, extent=(xMinDepth, xMaxDepth, yMinDepth, yMaxDepth), zorder=1, alpha=0.8)\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "        plt.colorbar(im, cax=cax,label='Depth (m)',extend='max')\n",
    "        plt.text(.02,.02,f'Projection in {epsgRast}', fontsize=8,\n",
    "             path_effects=[pe.withStroke(linewidth=3, foreground=\"white\")], transform=ax.transAxes,zorder=7)\n",
    "        gdfDamage.plot(ax=ax, edgecolor='grey', linewidth=0.25, facecolor='none')\n",
    "        ax.set_xlim(Longitude1-xbuffer,Longitude2+xbuffer)\n",
    "        ax.set_ylim(Latitude1-ybuffer,Latitude2+ybuffer)\n",
    "        ctx.add_basemap(ax=ax, crs=epsgRast, source=ctx.providers.OpenStreetMap.Mapnik, attribution_size='6', alpha=0.4)\n",
    "        txt = ax.texts[-1]\n",
    "        txt.set_position([0.99,0.98])\n",
    "        txt.set_ha('right')\n",
    "        txt.set_va('top')\n",
    "        if showOutlineFlag is True:\n",
    "            outlineGeometry.plot(ax=ax, edgecolor=outlineColour, linestyle=outlineStyle, linewidth=outlineThickness, facecolor=outlineFace, alpha=outlineAlpha, zorder=5)\n",
    "            if outlineLabelFlag is True:\n",
    "                outline_legend = mlines.Line2D([], [], color=outlineColour, linewidth=outlineThickness, label=outlineLabel)\n",
    "                ax.legend(handles=[outline_legend], loc=outlineLabelPosition, fontsize=outlineLabelSize, frameon=True)\n",
    "        if imageSaveFlag is True:\n",
    "            plt.savefig(os.path.join(dirImages, f'{saveName}_buildingoutline_floodmap_{RP}RP.png'), bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        # Map depths > 0 at building level\n",
    "        gdf_filtered = gdfDamage[(gdfDamage['MeanDepth'] > 0) | (gdfDamage['MinDepth'] > 0) | (gdfDamage['MaxDepth'] > 0)]\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "        plt.title(f'Mean flood depth at building locations \\n derived from the flood map with {RP}-year return period')\n",
    "        plt.xlabel('Longitude', fontsize='small')\n",
    "        plt.ylabel('Latitude', fontsize='small')\n",
    "        plot = gdf_filtered.plot(column='MeanDepth', vmin=0, vmax=maxDepthLegend, cmap=cmap_h2o, ax=ax)\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "        plt.colorbar(plot.collections[0], cax=cax,label='Depth (m)',extend='max')\n",
    "        plt.text(.02,.02,f'Projection in {epsgRast}', fontsize=8,\n",
    "             path_effects=[pe.withStroke(linewidth=3, foreground=\"white\")], transform=ax.transAxes,zorder=7)\n",
    "        ax.set_xlim(Longitude1-xbuffer,Longitude2+xbuffer)\n",
    "        ax.set_ylim(Latitude1-ybuffer,Latitude2+ybuffer)\n",
    "        ctx.add_basemap(ax=ax, crs=gdf_filtered.crs, source=ctx.providers.OpenStreetMap.Mapnik, attribution_size='6', alpha=0.9)\n",
    "        txt = ax.texts[-1]\n",
    "        txt.set_position([0.99,0.98])\n",
    "        txt.set_ha('right')\n",
    "        txt.set_va('top')  \n",
    "        if showOutlineFlag is True:\n",
    "            outlineGeometry.plot(ax=ax, edgecolor=outlineColour, linestyle=outlineStyle, linewidth=outlineThickness, facecolor=outlineFace, alpha=outlineAlpha, zorder=5)\n",
    "            if outlineLabelFlag is True:\n",
    "                outline_legend = mlines.Line2D([], [], color=outlineColour, linewidth=outlineThickness, label=outlineLabel)\n",
    "                ax.legend(handles=[outline_legend], loc=outlineLabelPosition, fontsize=outlineLabelSize, frameon=True)\n",
    "        if imageSaveFlag is True:\n",
    "            plt.savefig(os.path.join(dirImages, f'{saveName}_building_flooddepth_{RP}RP.png'), bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "    # Save the updated geodataframe to a shapefile\n",
    "    shpDepths = os.path.join(dirResults, f'{saveName}_Depths_Building_RP{RP}.shp')\n",
    "    gdfDamage.to_file(shpDepths, driver='ESRI Shapefile')\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80fca2c-4966-4c55-a52a-ab4a1a9c8fa9",
   "metadata": {
    "id": "a80fca2c-4966-4c55-a52a-ab4a1a9c8fa9"
   },
   "source": [
    "### Calculating economic damage to buildings\n",
    "Based on the flood water depths, the damage to the buildings (reconstruction costs) and for its contents are determined.\n",
    "- First the fractional building damage is calculated applying the JRC damage functions for each classifiction (residential, commerical, etc).\n",
    "- Then the fractional damage is multiplied with the maximum damage value per square meter and the building footprint area in meters and written to a shapefile.\n",
    "- The damages in millions of Euros summed over all of the classes and plotted for each return period level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f071821",
   "metadata": {},
   "outputs": [],
   "source": [
    "for RP in ReturnPeriods:\n",
    "    # Read Building Water Depth Shapefile\n",
    "    shpDepths = os.path.join(dirResults, f'{saveName}_Depths_Building_RP{RP}.shp')\n",
    "    gdfDamage = gpd.read_file(shpDepths)\n",
    "\n",
    "    for Depth in Depths:\n",
    "\n",
    "        if Depth == 'Mean':\n",
    "            depthStat = 'mean'\n",
    "        elif Depth == 'Max':\n",
    "            depthStat = 'max'\n",
    "        elif Depth == 'Min':\n",
    "            depthStat = 'min'\n",
    "        else:\n",
    "            print('Depth statistic does not exist.')\n",
    "            print('  Current options are Mean, Max, and Min')\n",
    "            sys.exit()\n",
    "\n",
    "        print(f'Computing damage for {Depth.lower()} building depth. RP={str(RP)}.')\n",
    "        \n",
    "        statName = depthStat.title() + 'Depth'\n",
    "\n",
    "        # Compute the damage factor for each building class\n",
    "\n",
    "        gdfDamage['TotDamage'] = 0  # Initialize TotalDamage column\n",
    "\n",
    "        for dmgClass in DamageClasses:\n",
    "\n",
    "            bldgDamage='f'+dmgClass[:3].upper()+depthStat\n",
    "            dmgName = 'Dmg'+bldgDamage[1:]\n",
    "            # Damage factors and maximum damage value including contents\n",
    "            if dmgClass == 'Residential':\n",
    "                gdfDamage[bldgDamage] = DamageFunction(gdfDamage[statName], coefs_RES)\n",
    "                MaxDmg = MaxDmgRES.sum()\n",
    "            elif dmgClass == 'Commercial':\n",
    "                gdfDamage[bldgDamage] = DamageFunction(gdfDamage[statName], coefs_COM)\n",
    "                MaxDmg = MaxDmgCOM.sum()\n",
    "            elif dmgClass == 'Industrial':\n",
    "                gdfDamage[bldgDamage] = DamageFunction(gdfDamage[statName], coefs_IND)\n",
    "                MaxDmg = MaxDmgIND.sum()\n",
    "            elif dmgClass == 'Transportation':\n",
    "                gdfDamage[bldgDamage] = DamageFunction(gdfDamage[statName], coefs_TRS)\n",
    "                MaxDmg = MaxDmgTRS.sum()\n",
    "            elif dmgClass == 'Agriculture':\n",
    "                gdfDamage[bldgDamage] = DamageFunction(gdfDamage[statName], coefs_AGR)\n",
    "                MaxDmg = MaxDmgAGR.sum()\n",
    "            elif dmgClass == 'Universal':\n",
    "                gdfDamage[bldgDamage] = DamageFunction(gdfDamage[statName], coefs_UNI)\n",
    "                MaxDmg = MaxDmgUNI.sum()\n",
    "            else:\n",
    "                gdfDamage[bldgDamage] = DamageFunction(gdfDamage[statName], coefs_UNI)\n",
    "                MaxDmg = MaxDmgUNI.sum()\n",
    "\n",
    "            # Damage computation\n",
    "            gdfDamage.loc[gdfDamage['bldgClass'] != dmgClass, bldgDamage] = 0\n",
    "            gdfDamage[dmgName] = gdfDamage[bldgDamage] * gdfDamage['Area_m2'] * MaxDmg\n",
    "\n",
    "            # Add TotalDamage in millions of â‚¬\n",
    "            gdfDamage['TotDamage'] += gdfDamage[dmgName] / 10**6\n",
    "\n",
    "        gdfDamage.to_file(shpDepths, driver='ESRI Shapefile')\n",
    "\n",
    "        # Plotting the GeoDataFrame with filtered values\n",
    "        if RP in ImageReturnPeriod and flagBuildingDmg is True:\n",
    "            fig, ax = plt.subplots()\n",
    "            plt.title(f'Damage to buildings by {Depth.lower()} flood depth\\nbased on the flood map with {str(RP)}-year return period')\n",
    "            plt.xlabel('Longitude', fontsize='small')\n",
    "            plt.ylabel('Latitude', fontsize='small')\n",
    "            plot = gdfDamage.plot(column='TotDamage', cmap=cmap_dmg, ax=ax,zorder=2)\n",
    "            \n",
    "            divider = make_axes_locatable(ax)\n",
    "            cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "            plt.colorbar(plot.collections[0], cax=cax,label='Damage (Mil â‚¬)',extend='max')\n",
    "            \n",
    "            plt.text(.02,.02,f'Projection in {gdfDamage.crs}', fontsize=8,path_effects=[pe.withStroke(linewidth=3, foreground=\"white\")], transform=ax.transAxes,zorder=7)\n",
    "            ax.set_xlim(Longitude1-xbuffer,Longitude2+xbuffer)\n",
    "            ax.set_ylim(Latitude1-ybuffer,Latitude2+ybuffer)\n",
    "            ctx.add_basemap(ax=ax, crs=gdfDamage.crs, source=ctx.providers.OpenStreetMap.Mapnik, attribution_size='6', alpha=0.9)\n",
    "            txt = ax.texts[-1]\n",
    "            txt.set_position([0.99,0.98])\n",
    "            txt.set_ha('right')\n",
    "            txt.set_va('top')\n",
    "            if showOutlineFlag is True:\n",
    "                outlineGeometry.plot(ax=ax, edgecolor=outlineColour, linestyle=outlineStyle, linewidth=outlineThickness, facecolor=outlineFace, alpha=outlineAlpha, zorder=5)\n",
    "                if outlineLabelFlag is True:\n",
    "                    outline_legend = mlines.Line2D([], [], color=outlineColour, linewidth=outlineThickness, label=outlineLabel)\n",
    "                    ax.legend(handles=[outline_legend], loc=outlineLabelPosition, fontsize=outlineLabelSize, frameon=True)\n",
    "            if imageSaveFlag is True:\n",
    "                plt.savefig(os.path.join(dirImages, f'{saveName}_building_damage_{Depth.lower()}depth_{RP}RP.png'), bbox_inches='tight')\n",
    "            plt.show()\n",
    "\n",
    "print('Done computing damage for each building')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ee07ed-8a73-4db7-8a76-b659ada3c935",
   "metadata": {
    "id": "70ee07ed-8a73-4db7-8a76-b659ada3c935"
   },
   "source": [
    "### Total damage to buildings\n",
    "In this section the total damage for the region of interest is summed and written to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233c6ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nDmg = np.append(DamageClasses, 'Total')\n",
    "\n",
    "dfDMGs = pd.DataFrame(columns=[])\n",
    "dfDMGs.index = nDmg\n",
    "dfDMGs.index.name = 'Building Class'\n",
    "\n",
    "for Depth in Depths:\n",
    "\n",
    "    if Depth not in ['Mean', 'Max', 'Min']:\n",
    "        print('Depth statistic does not exist.')\n",
    "        print('  Current options are Mean, Minimum, and Maximum')\n",
    "        sys.exit()\n",
    "\n",
    "    print(f'Damage for {Depth} depth')\n",
    "\n",
    "    for RP in ReturnPeriods:\n",
    "\n",
    "        shpOSM = os.path.join(dirResults, f'{saveName}_Depths_Building_RP{RP}.shp')\n",
    "        gdfOSM = gpd.read_file(shpOSM)\n",
    "\n",
    "        vDmg = pd.DataFrame(columns=[])\n",
    "        for dmgClass in DamageClasses:\n",
    "            dmgName = f'DmgTRS{Depth.lower()}' if dmgClass == 'Transportation' else \\\n",
    "            f'Dmg{dmgClass[:3].upper()}{Depth.lower()}'\n",
    "            vDmg = np.append(vDmg, gdfOSM[dmgName].sum())\n",
    "\n",
    "        totDmg = sum(vDmg)\n",
    "        vDmg = np.append(vDmg, totDmg)\n",
    "        totDmg_byclass = pd.DataFrame(vDmg)\n",
    "        # Assign names to the dataframe headers\n",
    "        totDmg_byclass.columns = [f'{RP}-yr']\n",
    "        totDmg_byclass.index = [nDmg]\n",
    "\n",
    "        # Compute the total damage across the entire area of interest\n",
    "        print(f'  RP={RP}: Total damage (â‚¬) = {round(totDmg, 3)}')\n",
    "\n",
    "        dfDMGs[f'{RP}-yr'] = np.array(totDmg_byclass)\n",
    "\n",
    "    damage_csv_filename = os.path.join(dirResults, f'{saveName}_DamageTotal_{Depth}.csv')\n",
    "    dfDMGs.to_csv(damage_csv_filename)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d29647-3501-4c1a-8234-3a8dbcee6a31",
   "metadata": {
    "id": "91d29647-3501-4c1a-8234-3a8dbcee6a31"
   },
   "source": [
    "### Expected annual damage\n",
    "In this section the plot of building damages vs return periods of the flood maps is generated.\n",
    "Moreover, by integrating the curve, an estimate of the expected annual damage (EAD) in millions of Euros is provided. EAD is the damage that the region would expect on average in any given year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ebc843-17bf-45d2-aa6d-47cf20cb012b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "76ebc843-17bf-45d2-aa6d-47cf20cb012b",
    "outputId": "653d0a6f-b2b0-4166-a034-543a73b9b255"
   },
   "outputs": [],
   "source": [
    "max_yaxis=0\n",
    "vert_spacer=0\n",
    "for Depth in Depths:\n",
    "    if Depth == 'Mean':\n",
    "        depthStat = 'mean'\n",
    "    elif Depth == 'Max':\n",
    "        depthStat = 'max'\n",
    "    elif Depth == 'Min':\n",
    "        depthStat = 'min'\n",
    "    else:\n",
    "        print('Depth statistic does not exist.')\n",
    "        print('  Current options are Mean, Minimum, and Maximum')\n",
    "        sys.exit()\n",
    "\n",
    "    # Load damage data for the current depth statistic\n",
    "    damage_csv_filename = os.path.join(dirResults, f'{saveName}_DamageTotal_{Depth}.csv')\n",
    "    dfDMGs = pd.read_csv(damage_csv_filename, index_col=0)\n",
    "\n",
    "    # Compute the total Estimated Annual Damage (EAD) over all return periods\n",
    "    probRPs = 1 / np.array(ReturnPeriods)\n",
    "    iTot = dfDMGs.index.get_loc('Total')\n",
    "    EAD = 0\n",
    "    for iRP in range(len(ReturnPeriods)-1):\n",
    "        diffRP = probRPs[iRP] - probRPs[iRP+1]\n",
    "        avgDMG = (dfDMGs.iloc[iTot, iRP+1] + dfDMGs.iloc[iTot, iRP]) / 2\n",
    "        EAD = EAD + avgDMG * diffRP\n",
    "        graphText = f'{Depth} Expected Annual Damage: {round(EAD/10**6, 2)} Mil â‚¬'\n",
    "\n",
    "    # Plot estimated direct damage vs exceedance probability\n",
    "    if flagBuildingDmgGraph is True:\n",
    "        totDmg = dfDMGs.loc['Total'] / 10**6\n",
    "        max_yaxis_current=totDmg.max()\n",
    "        max_yaxis=max(max_yaxis,max_yaxis_current)\n",
    "        plt.plot(np.array(ReturnPeriods), totDmg, marker='o', linestyle='-')\n",
    "        plt.ylim(0)\n",
    "        plt.grid(which='both', linestyle=':', linewidth=0.5, color='gray',dashes=(1,5))\n",
    "        plt.xlabel('Event return period (Years)')\n",
    "        plt.ylabel('Estimated Direct Damage (Mil â‚¬)')\n",
    "        plt.text(0.96, 0.05+vert_spacer, graphText, transform=plt.gca().transAxes, fontsize=10,\n",
    "             verticalalignment='bottom', horizontalalignment='right', bbox=dict(facecolor='white', alpha=0.5, edgecolor='black'))\n",
    "    print(graphText)\n",
    "    vert_spacer=vert_spacer+0.08\n",
    "yaxis_buffer=50 #This sets the y axis max to be the smallest multiple larger than the max value (eg: if yaxis_buffer=100, and the max value is 280, the yaxis max will be 300)\n",
    "plt.ylim(0, ((max_yaxis // yaxis_buffer) + 1) * yaxis_buffer)\n",
    "if len(Depths) > 1:\n",
    "    plt.legend(Depths,title=\"Flood depth used at\\nbuilding location:\",fontsize='small',title_fontsize='small',\n",
    "           loc='upper left', bbox_to_anchor=(1, 1),\n",
    "          fancybox=True)\n",
    "    plt.title('Estimated damage to buildings based on\\nflood depth at building locations')\n",
    "else:\n",
    "    plt.title(f'Estimated damage to buildings based on\\n{Depth.lower()} flood depth at building locations')\n",
    "if imageSaveFlag is True:\n",
    "    plt.savefig(os.path.join(dirImages, f'{saveName}_damage_graph.png'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a412f7ac",
   "metadata": {},
   "source": [
    "### Critical Infrastructure\n",
    "In order to visualise the exposure of critical infrastructure for the area of interest, the OSM dataset is used:\n",
    "- Markers and colours are attributed for each type of critical infrastructure.\n",
    "- Flood water depths are read.\n",
    "- Critical infrastructure and floods are mapped together.\n",
    "\n",
    "Note that preference will be given to amenity classes over building classes, to avoid duplicates. Therefore there might be cases where certain OSM entries will not show up in the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec8d175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the critical column is boolean\n",
    "gdfOSMreclass['critInfrastructure'] = gdfOSMreclass['critInfrastructure'].infer_objects(copy=False)\n",
    "\n",
    "for RP in ImageReturnPeriod:\n",
    "    rastDepths = os.path.join(dirDepths, f'{saveName}_Europe_RP{RP}_filled_depth.tif')\n",
    "    # Read the TIFF image\n",
    "    with rasterio.open(rastDepths) as src:\n",
    "        rDepths = src.read(1)  # Reading the first band\n",
    "        rDepths = np.ma.masked_where((rDepths < -999) | (rDepths > 1000), rDepths)\n",
    "        # Compute the maximum value from the masked data\n",
    "        max_depth  = rDepths.max()\n",
    "        if customMaxDepthLegend == -1:\n",
    "            maxDepthLegend = ((max_depth // 1) + 1)\n",
    "        else:\n",
    "            maxDepthLegend=customMaxDepthLegend\n",
    "        missing_data_value = src.nodata\n",
    "\n",
    "    fig=plt.figure()\n",
    "    ax = plt.axes()\n",
    "    im = ax.imshow(rDepths, vmin=0, vmax=maxDepthLegend, cmap=cmap_h2o, extent=(xMinDepth, xMaxDepth, yMinDepth, yMaxDepth),\n",
    "                zorder=1, alpha=0.6)\n",
    "    plt.title(f'Critical infrastructure exposure to river floods with {RP}-year return period')\n",
    "    divider = make_axes_locatable(ax)\n",
    "    plt.xlabel('Longitude', fontsize='small')\n",
    "    plt.ylabel('Latitude', fontsize='small')\n",
    "    cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "    plt.colorbar(im, cax=cax,label='Depth (m)',extend='max')\n",
    "    plt.text(.02,.02,f'Projection in {gdfDamage.crs}', fontsize=8,\n",
    "                path_effects=[pe.withStroke(linewidth=3, foreground=\"white\")], transform=ax.transAxes,zorder=7)\n",
    "\n",
    "    # Collect critical buildings for all building types\n",
    "    for building_type, props in critMarkersColours.items():\n",
    "        markerItem = props['marker']\n",
    "        colourItem = props['color']\n",
    "        # Check for building type in 'amenity' or 'building' columns\n",
    "        if building_type in gdfOSMreclass['amenity'].unique():\n",
    "            crit_buildings = gdfOSMreclass[gdfOSMreclass['amenity'] == building_type]\n",
    "        elif building_type in gdfOSMreclass['building'].unique():\n",
    "            crit_buildings = gdfOSMreclass[gdfOSMreclass['building'] == building_type]\n",
    "        else:\n",
    "            continue\n",
    "        crit_buildings_geometry = crit_buildings.geometry\n",
    "        crit_buildings_geometry = crit_buildings_geometry.to_crs('EPSG:3857')\n",
    "        crit_buildings_centroids = crit_buildings_geometry.centroid\n",
    "        transformer = Transformer.from_crs('EPSG:3857', gdfOSMreclass.crs, always_xy=True)\n",
    "        reprojected_centroids = []\n",
    "        for centroid in crit_buildings_centroids:\n",
    "            x, y = transformer.transform(centroid.x, centroid.y)  # Reproject the coordinates\n",
    "            reprojected_centroids.append(Point(x, y))\n",
    "        crit_buildings_centroids_reprojected = gpd.GeoSeries(reprojected_centroids, crs=gdfOSMreclass.crs)\n",
    "        ax.scatter(crit_buildings_centroids_reprojected.x, crit_buildings_centroids_reprojected.y, color=colourItem, marker=markerItem, s=100,\n",
    "                linewidths=.8, edgecolors='k', label=f'{building_type.capitalize()}',zorder=6) #change s value for the size of markers\n",
    "    # Optionally, add basemap if needed\n",
    "    ax.set_xlim(Longitude1-xbuffer,Longitude2+xbuffer)\n",
    "    ax.set_ylim(Latitude1-ybuffer,Latitude2+ybuffer)\n",
    "    ctx.add_basemap(ax=ax, crs=gdfDamage.crs, source=ctx.providers.OpenStreetMap.Mapnik, attribution_size='6', alpha=0.5)\n",
    "    txt = ax.texts[-1]\n",
    "    txt.set_position([0.99,0.98])\n",
    "    txt.set_ha('right')\n",
    "    txt.set_va('top')\n",
    "    #Legend\n",
    "    if showOutlineFlag is True:\n",
    "        outlineGeometry.plot(ax=ax, edgecolor=outlineColour, linestyle=outlineStyle, linewidth=outlineThickness, facecolor=outlineFace, alpha=outlineAlpha, zorder=5)\n",
    "    if outlineLabelFlag is True:\n",
    "        outline_legend = mlines.Line2D([], [], color=outlineColour, linewidth=outlineThickness, label=outlineLabel)\n",
    "        legend_outline=ax.legend(handles=[outline_legend], loc=outlineLabelPosition, fontsize=outlineLabelSize, frameon=True)\n",
    "\n",
    "    legend = ax.legend(loc='upper center', ncol=4, bbox_to_anchor=(0.5, -0.11),\n",
    "                        title='Critical infrastructure type:')\n",
    "    ax.tick_params(direction='out', length=8, width=.8,\n",
    "                    labelsize=7)\n",
    "    \n",
    "    if outlineLabelFlag is True:\n",
    "        ax.add_artist(legend_outline)\n",
    "        \n",
    "    if imageSaveFlag is True:\n",
    "        plt.savefig(os.path.join(dirImages, f'{saveName}_criticalinfrastructure_{RP}RP.png'), bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabd60b7",
   "metadata": {},
   "source": [
    "### Exposed population\n",
    "Based on the flood depth maps, the exposed population is determined.\n",
    "- The population and flood rasters are compared.\n",
    "- The exposed population is written to a CSV file.\n",
    "- A map of the exposed popoulation is produced.\n",
    "- The exposed population is plotted against the flood map return period.\n",
    "\n",
    "Expected annual exposed population is also calculated, representing the expected number of people exposed on average in any given year.\n",
    "\n",
    "Please note that due to the resolution of both the population and the flood maps, it might be that part of the population appears to be over a water body (eg: a river) and is counted towards the overall exposed statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5777fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('  Loading population for selected bounds:')\n",
    "rastPopulation_zoom = rastPopulation.replace('.tif', f'_{saveName}.tif')\n",
    "print(f'  {rastPopulation_zoom}')\n",
    "\n",
    "# Load the population data within the specified bounds\n",
    "with rasterio.open(rastPopulation) as src:\n",
    "    window = from_bounds(xMinPop, yMinPop, xMaxPop, yMaxPop, src.transform)\n",
    "    rPopulation = src.read(1, window=window)\n",
    "    rPopulation = np.ma.masked_where(rPopulation < 0.0, rPopulation)\n",
    "    missing_data_value = src.nodata\n",
    "\n",
    "    # Save the zoomed population raster\n",
    "    with rasterio.open(\n",
    "        rastPopulation_zoom,\n",
    "        'w',\n",
    "        driver='GTiff',\n",
    "        height=rPopulation.shape[0],\n",
    "        width=rPopulation.shape[1],\n",
    "        count=1,\n",
    "        dtype=rPopulation.dtype,\n",
    "        crs=src.crs,\n",
    "        transform=src.window_transform(window),\n",
    "        nodata=missing_data_value\n",
    "    ) as dst:\n",
    "        dst.write(rPopulation, 1)\n",
    "\n",
    "\n",
    "#Initialise population exposed array\n",
    "exposedPop = []\n",
    "\n",
    "# Process each return period\n",
    "for RP in ReturnPeriods:\n",
    "    rastDepths_zoom = os.path.join(dirDepths, f'{saveName}_Europe_RP{RP}_filled_depth.tif')\n",
    "    with rasterio.open(rastDepths_zoom) as flood_src:\n",
    "        rastDepths_data = flood_src.read(1)\n",
    "\n",
    "        # Reproject the population raster to match the projection of the depths raster\n",
    "        with rasterio.open(rastPopulation_zoom) as pop_src:\n",
    "            pop_data = pop_src.read(1)\n",
    "            pop_transform, pop_width, pop_height = calculate_default_transform(\n",
    "                pop_src.crs, flood_src.crs, pop_src.width, pop_src.height, *pop_src.bounds\n",
    "            )\n",
    "            pop_profile = pop_src.profile.copy()\n",
    "            pop_profile.update({\n",
    "                'crs': flood_src.crs,\n",
    "                'transform': pop_transform,\n",
    "                'width': pop_width,\n",
    "                'height': pop_height\n",
    "            })\n",
    "\n",
    "            # Create an empty array to store the reprojected population data\n",
    "            reprojected_pop_data = np.zeros((flood_src.height, flood_src.width), dtype=pop_data.dtype)\n",
    "            reproject(\n",
    "                pop_data,\n",
    "                reprojected_pop_data,\n",
    "                src_transform=pop_src.transform,\n",
    "                src_crs=pop_src.crs,\n",
    "                dst_transform=pop_transform,\n",
    "                dst_crs=flood_src.crs,\n",
    "                resampling=Resampling.nearest\n",
    "            )\n",
    "\n",
    "            # Find the spatial intersection between the depths raster and the reprojected population raster\n",
    "            exposed_population = np.where(rastDepths_data > minDepthExposed, 1, 0) * reprojected_pop_data\n",
    "\n",
    "            # Sum the exposed population\n",
    "            total_exposed = np.sum(exposed_population)\n",
    "            exposedPop.append(total_exposed)\n",
    "\n",
    "            # Save the result raster for the exposed population\n",
    "            result_raster = os.path.join(dirResultsPop, os.path.basename(rastDepths_zoom).replace('.tif', '_exposed_population.tif'))\n",
    "            with rasterio.open(\n",
    "                result_raster,\n",
    "                'w',\n",
    "                driver='GTiff',\n",
    "                height=exposed_population.shape[0],\n",
    "                width=exposed_population.shape[1],\n",
    "                count=1,\n",
    "                dtype=exposed_population.dtype,\n",
    "                crs=flood_src.crs,\n",
    "                transform=flood_src.transform,\n",
    "            ) as dst:\n",
    "                dst.write(exposed_population, 1)\n",
    "    if len(exposed_population.shape) == 3:\n",
    "        height, width = exposed_population.shape[1], exposed_population.shape[2]\n",
    "    elif len(exposed_population.shape) == 2:\n",
    "        height, width = exposed_population.shape\n",
    "    xMinExpPop, yMinExpPop, xMaxExpPop, yMaxExpPop = array_bounds(height, width, out_transform)   \n",
    "\n",
    "    if RP in ImageReturnPeriod and flagPopulationExp is True:\n",
    "        # Plot rasters\n",
    "        fig, ax = plt.subplots()\n",
    "        plt.title(f'Exposed population for the river flood event with {RP}-year return period\\n(Population statistics based on estimate for the year {PopYear})')\n",
    "        im = ax.imshow(np.ma.masked_where((exposed_population <= 0), exposed_population), cmap=cmap_pop, extent=(xMinExpPop, xMaxExpPop, yMinExpPop, yMaxExpPop),\n",
    "                       zorder=2,alpha=0.8)\n",
    "        plt.xlabel('Longitude', fontsize='small')\n",
    "        plt.ylabel('Latitude', fontsize='small')\n",
    "       \n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "        plt.colorbar(im, cax=cax, label='People per 3 arcseconds\\u00B2', extend='max')\n",
    "        plt.text(0, -.27, f'Exposed if Water Depth >{minDepthExposed}m', transform=ax.transAxes, fontsize=8,\n",
    "             verticalalignment='top', horizontalalignment='left', bbox=dict(facecolor='white', alpha=0.5, edgecolor='black'))\n",
    "        plt.text(.02,.02,f'Projection in {epsgRastPop}', fontsize=8,path_effects=[pe.withStroke(linewidth=3, foreground=\"white\")], transform=ax.transAxes,zorder=7)\n",
    "        ax.set_xlim(Longitude1-xbuffer,Longitude2+xbuffer)\n",
    "        ax.set_ylim(Latitude1-ybuffer,Latitude2+ybuffer)\n",
    "        ctx.add_basemap(ax=ax, crs=epsgRastPop, source=ctx.providers.OpenStreetMap.Mapnik, attribution_size='6', alpha=1)\n",
    "        txt = ax.texts[-1]\n",
    "        txt.set_position([0.99,0.98])\n",
    "        txt.set_ha('right')\n",
    "        txt.set_va('top')\n",
    "        if showOutlineFlag is True:\n",
    "            outlineGeometry.plot(ax=ax, edgecolor=outlineColour, linestyle=outlineStyle, linewidth=outlineThickness, facecolor=outlineFace, alpha=outlineAlpha, zorder=5)\n",
    "        if outlineLabelFlag is True:\n",
    "            outline_legend = mlines.Line2D([], [], color=outlineColour, linewidth=outlineThickness, label=outlineLabel)\n",
    "            legend_outline=ax.legend(handles=[outline_legend], loc=outlineLabelPosition, fontsize=outlineLabelSize, frameon=True)\n",
    "        if imageSaveFlag is True:\n",
    "            plt.savefig(os.path.join(dirImages, f'{saveName}_popexposed_map_{RP}RP.png'), bbox_inches='tight')\n",
    "        plt.show()              \n",
    "\n",
    "\n",
    "# Compute the total Estimated Annual Exposed Population (EAEP) over all return periods\n",
    "EAEP = 0\n",
    "for iRP in range(len(ReturnPeriods)-1):\n",
    "    diffRP = probRPs[iRP] - probRPs[iRP+1]\n",
    "    avgPOP = (exposedPop[iRP+1] + exposedPop[iRP]) / 2\n",
    "    EAEP = EAEP + avgPOP * diffRP\n",
    "\n",
    "if flagPopulationExpGraph is True:\n",
    "    plt.plot(np.array(ReturnPeriods), exposedPop, marker='o', linestyle='-')\n",
    "    plt.ylim(0)\n",
    "    plt.grid(which='both', linestyle=':', linewidth=0.5, color='gray',dashes=(1,5))\n",
    "    plt.xlabel('Event Return Period (Years)')\n",
    "    plt.ylabel('People')\n",
    "    plt.title(f'Estimated exposed population per flood event return period\\n(Population statistics based on estimate for the year {PopYear})')\n",
    "    graphText = f'Expected annual population exposed: {round(EAEP)} people.'\n",
    "    plt.text(0.96, 0.05, graphText, transform=plt.gca().transAxes, fontsize=10,\n",
    "             verticalalignment='bottom', horizontalalignment='right', bbox=dict(facecolor='white', alpha=0.5, edgecolor='black'))\n",
    "    \n",
    "    if imageSaveFlag is True:\n",
    "        plt.savefig(os.path.join(dirImages, f'{saveName}_popexposed_graph.png'), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "print(graphText)\n",
    "\n",
    "#CSV FILE\n",
    "dfPOP = pd.DataFrame(columns=[])\n",
    "dfPOP.index = ReturnPeriods\n",
    "dfPOP.index.name = 'Flood event return period (years)'\n",
    "dfPOP['People Exposed'] = exposedPop\n",
    "population_csv_filename = os.path.join(dirResultsPop, f'{saveName}_ExposedPopulationTotal.csv')\n",
    "dfPOP.to_csv(population_csv_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2879e535",
   "metadata": {},
   "source": [
    "### Displaced population\n",
    "Based on the flood depth maps, the displaced population is a subset of the exposed population that experience flood depths above a given threshold. \n",
    "- The population and flood rasters are compared.\n",
    "- The displaced population is written to a CSV file.\n",
    "- A map of the displaced population is produced.\n",
    "- The plot of displaced population vs flood map return period is produced.\n",
    "\n",
    "Expected annual displaced population is also calculated, representing the expected number of people displaced on average per year.\n",
    "\n",
    "Please note that due to the resolution of both the population and the flood maps, it might be that part of the population appears to be over a water body (eg: a river) and is counted towards the overall displaced statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e4917e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise displaced population array\n",
    "displacedPop = []\n",
    "# Process each return period\n",
    "for RP in ReturnPeriods:\n",
    "    rastDepths_zoom = os.path.join(dirDepths, f'{saveName}_Europe_RP{RP}_filled_depth.tif')\n",
    "    with rasterio.open(rastDepths_zoom) as flood_src:\n",
    "        rastDepths_data = flood_src.read(1)\n",
    "\n",
    "        # Reproject the population raster to match the projection of the depths raster\n",
    "        with rasterio.open(rastPopulation_zoom) as pop_src:\n",
    "            pop_data = pop_src.read(1)\n",
    "            pop_transform, pop_width, pop_height = calculate_default_transform(\n",
    "                pop_src.crs, flood_src.crs, pop_src.width, pop_src.height, *pop_src.bounds\n",
    "            )\n",
    "            pop_profile = pop_src.profile.copy()\n",
    "            pop_profile.update({\n",
    "                'crs': flood_src.crs,\n",
    "                'transform': pop_transform,\n",
    "                'width': pop_width,\n",
    "                'height': pop_height\n",
    "            })\n",
    "\n",
    "            # Create an empty array to store the reprojected population data\n",
    "            reprojected_pop_data = np.zeros((flood_src.height, flood_src.width), dtype=pop_data.dtype)\n",
    "            reproject(\n",
    "                pop_data,\n",
    "                reprojected_pop_data,\n",
    "                src_transform=pop_src.transform,\n",
    "                src_crs=pop_src.crs,\n",
    "                dst_transform=pop_transform,\n",
    "                dst_crs=flood_src.crs,\n",
    "                resampling=Resampling.nearest\n",
    "            )\n",
    "\n",
    "            # Find the spatial intersection between the depths raster and the reprojected population raster\n",
    "            displaced_population = np.where(rastDepths_data > minDepthDisplaced, 1, 0) * reprojected_pop_data\n",
    "\n",
    "            # Sum the exposed population\n",
    "            total_displaced = np.sum(displaced_population)\n",
    "            displacedPop.append(total_displaced)\n",
    "\n",
    "            # Save the result raster for the exposed population\n",
    "            result_raster = os.path.join(dirResultsPop, os.path.basename(rastDepths_zoom).replace('.tif', '_displaced_population.tif'))\n",
    "            with rasterio.open(\n",
    "                result_raster,\n",
    "                'w',\n",
    "                driver='GTiff',\n",
    "                height=displaced_population.shape[0],\n",
    "                width=displaced_population.shape[1],\n",
    "                count=1,\n",
    "                dtype=displaced_population.dtype,\n",
    "                crs=flood_src.crs,\n",
    "                transform=flood_src.transform,\n",
    "            ) as dst:\n",
    "                dst.write(displaced_population, 1)\n",
    "    if len(displaced_population.shape) == 3:\n",
    "        height, width = displaced_population.shape[1], displaced_population.shape[2]\n",
    "    elif len(displaced_population.shape) == 2:\n",
    "        height, width = displaced_population.shape\n",
    "    xMinDisPop, yMinDisPop, xMaxDisPop, yMaxDisPop = array_bounds(height, width, out_transform)  \n",
    "\n",
    "    if RP in ImageReturnPeriod and flagPopulationDis is True:\n",
    "    # Plot rasters\n",
    "        fig, ax = plt.subplots()\n",
    "        plt.title(f'Displaced population for the river flood event with {RP}-year return period\\n(Population statistics based on estimate for the year {PopYear})')\n",
    "        im = ax.imshow(np.ma.masked_where((displaced_population <= 0), displaced_population), cmap=cmap_pop, extent=(xMinDisPop, xMaxDisPop, yMinDisPop, yMaxDisPop),\n",
    "                       zorder=2,alpha=0.8)\n",
    "        plt.xlabel('Longitude', fontsize='small')\n",
    "        plt.ylabel('Latitude', fontsize='small')\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "        plt.colorbar(im, cax=cax, label='People per 3 arcseconds\\u00B2', extend='max')\n",
    "        plt.text(0.00, -0.27, f'Displaced if flood depth >{minDepthDisplaced}m', transform=ax.transAxes, fontsize=8,\n",
    "             verticalalignment='top', horizontalalignment='left', bbox=dict(facecolor='white', alpha=0.5, edgecolor='black'))\n",
    "        plt.text(.02,.02,f'Projection in {epsgRastPop}', fontsize=8,path_effects=[pe.withStroke(linewidth=3, foreground=\"white\")], transform=ax.transAxes,zorder=7)\n",
    "        ax.set_xlim(Longitude1-xbuffer,Longitude2+xbuffer)\n",
    "        ax.set_ylim(Latitude1-ybuffer,Latitude2+ybuffer)\n",
    "        ctx.add_basemap(ax=ax, crs=epsgRastPop, source=ctx.providers.OpenStreetMap.Mapnik, attribution_size='6', alpha=1)\n",
    "        txt = ax.texts[-1]\n",
    "        txt.set_position([0.99,0.98])\n",
    "        txt.set_ha('right')\n",
    "        txt.set_va('top')\n",
    "        if showOutlineFlag is True:\n",
    "            outlineGeometry.plot(ax=ax, edgecolor=outlineColour, linestyle=outlineStyle, linewidth=outlineThickness, facecolor=outlineFace, alpha=outlineAlpha, zorder=5)\n",
    "        if outlineLabelFlag is True:\n",
    "            outline_legend = mlines.Line2D([], [], color=outlineColour, linewidth=outlineThickness, label=outlineLabel)\n",
    "            legend_outline=ax.legend(handles=[outline_legend], loc=outlineLabelPosition, fontsize=outlineLabelSize, frameon=True)\n",
    "        if imageSaveFlag is True:\n",
    "            plt.savefig(os.path.join(dirImages, f'{saveName}_popdisplaced_map_{RP}RP.png'), bbox_inches='tight')\n",
    "        plt.show()              \n",
    "\n",
    "# Compute the total Estimated Annual Displaced Population (EADP) over all return periods\n",
    "EADP = 0\n",
    "for iRP in range(len(ReturnPeriods)-1):\n",
    "    diffRP = probRPs[iRP] - probRPs[iRP+1]\n",
    "    avgPOP = (displacedPop[iRP+1] + displacedPop[iRP]) / 2\n",
    "    EADP = EADP + avgPOP * diffRP\n",
    "\n",
    "if flagPopulationDisGraph is True:\n",
    "    plt.plot(np.array(ReturnPeriods), displacedPop, marker='o', linestyle='-')\n",
    "    plt.ylim(0)\n",
    "    plt.grid(which='both', linestyle=':', linewidth=0.5, color='gray',dashes=(1,5))\n",
    "    plt.xlabel('Event Return Period (Years)')\n",
    "    plt.ylabel('People')\n",
    "    plt.title(f'Estimated displaced population per flood event return period\\n(Population statistics based on estimate for the year {PopYear})')\n",
    "    graphText = f'Expected Annual Population Displaced: {round(EADP)} people.'\n",
    "    plt.text(0.96, 0.13, f'Displaced if flood depth >{minDepthDisplaced}m', transform=plt.gca().transAxes, fontsize=8,\n",
    "             verticalalignment='bottom', horizontalalignment='right', bbox=dict(facecolor='white', alpha=0.5, edgecolor='black'))\n",
    "    plt.text(0.96, 0.05, graphText, transform=plt.gca().transAxes, fontsize=10,\n",
    "             verticalalignment='bottom', horizontalalignment='right', bbox=dict(facecolor='white', alpha=0.5, edgecolor='black'))\n",
    "    if imageSaveFlag is True:\n",
    "        plt.savefig(os.path.join(dirImages, f'{saveName}_popdisplaced_graph.png'), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "print(graphText)\n",
    "\n",
    "#CSV FILE\n",
    "dfPOP = pd.DataFrame(columns=[])\n",
    "dfPOP.index = ReturnPeriods\n",
    "dfPOP.index.name = 'Event Return Period (years)'\n",
    "dfPOP['People Exposed'] = exposedPop\n",
    "population_csv_filename = os.path.join(dirResultsPop, f'{saveName}_DisplacedPopulationTotal.csv')\n",
    "dfPOP.to_csv(population_csv_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700967dc",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In the risk assessment:\n",
    "- Flood and population maps where generated. \n",
    "- By combining hazards with exposure and vulnerabilities the risk was computed\n",
    "  - Building damage maps and estimated yearly damage.\n",
    "  - Population displacement and estimated yearly displacement.\n",
    "- Moreover, overall population and critical infrastructure exposed were also showcased.\n",
    "\n",
    "`````{admonition} How do the results match with your expectations?\n",
    ":class: note dropdown\n",
    "Having knowledge of the location can help assess if the results match with the expectations. If not, why not? Is it due to data limitations or are there other reasons?\n",
    "\n",
    "For example known water defenses may affect the way flooding occurs, especially for low return periods.\n",
    "`````\n",
    "`````{admonition} Which limitations of datasets have significantly influenced the results?\n",
    ":class: note dropdown\n",
    "As aforementioned, there are [multiple limitations](#limitations) which have to be considered, and which are context-dependent. Each limitation may have minimal impacts on the results for your area, or alternatively, can be a major source of influence. It is important to reflect on how this can affect the results, and if its necessary to improve the datasets.\n",
    "`````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0b58fc",
   "metadata": {},
   "source": [
    "### Authors \n",
    "CMCC\n",
    "\n",
    "Main contributors:  \n",
    "Jeremy Pal, Davide Serrao"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
